
[{"content":"","date":"23 May 2025","externalUrl":null,"permalink":"/categories/blog/","section":"Categories","summary":"","title":"Blog","type":"categories"},{"content":"","date":"23 May 2025","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"23 May 2025","externalUrl":null,"permalink":"/tags/design/","section":"Tags","summary":"","title":"Design","type":"tags"},{"content":"","date":"23 May 2025","externalUrl":null,"permalink":"/","section":"Filippo Sanzeni","summary":"","title":"Filippo Sanzeni","type":"page"},{"content":"This week, technologists and designers worldwide fawned over images of Sir Jony Ive standing shoulder-to-shoulder (awkwardly half-hugging) with Sam Altman following OpenAI’s $6.4 billion (stock-only) acquisition of WithLove. Admittedly, The optics are delicious: one of design’s most revered figures is joining forces with AI’s most powerful architect, promising to “reimagine human-computer interaction”. Initially, I thought, oh well, finally, some good design in AI development. On a second take, this is nothing more than thinly-veneered data extraction.\nFor all the talk of “delight” and “human-centered design”, the acquisition stinks of recruiting cultural icons to sanctify monopolistic ambitions. The partnership’s rhetoric leans heavily on emotionally intelligent design, the kind that makes you whisper, “Somebody gave a damn about me” when unboxing a cable (at least that’s still included when purchasing a new doohickey, unlike charging bricks). But with LLMs emotions are increasingly mimicked, not earned. OpenAI’s prototypes will likely weaponise Ive’s design language to make surveillance feel like intimacy.\nThis is the apotheosis of what Shoshana Zuboff calls “surveillance capitalism” - the unilateral claiming of private human experience as free raw material for behavioural data. Let\u0026rsquo;s not forget that Altman’s other startup scans biometric data in exchange for cryptocurrency.\nThe WithLove (sorry, now called io) device, with its promise to be “fully aware of the user’s environment” and “see everything in users’ lives,” represents the logical endpoint of this trajectory. Inevitably these data points end up “packaged as prediction products and sold into behavioural futures markets”. Now imagine that surveillance apparatus rendered in crisp fonts, with rounded corners and a carbon-neutral supply chain. Chef’s kiss.\nEnshittification has never found a more elegant vessel. Here we will have a device that promises frictionless integration into daily life, wrapped in the design language that once convinced us that paying $1,000 for a phone was somehow liberating.\nThe Altman-Ive alliance embodies what Ron Salaj calls “theftploitation”, a system built on data theft and exploitation, where users willingly pay for their own influencing. The upcoming io device sounds to me like a masochistic contract. Users will clamor to be monitored, soothed by Ive’s design touches even as OpenAI monetises their behavioral data.\nThis acquisition will probably be effective. As Max von Thun observes, Big Tech firms are “buying themselves an insurance policy, ensuring that even if their own in-house AI efforts flop, their digital dominance will be maintained”. And exactly there lies where the Ive partnership becomes particularly insidious. By wrapping this monopolistic land grab in the design philosophy that gave us the iPhone, OpenAI is building aesthetic barriers. Who will compete with a device that feels better, looks better, and carries the cultural cachet of revolutionary design?\nShould we celebrate disguising surveillance as care?\n","date":"23 May 2025","externalUrl":null,"permalink":"/posts/on-designifying-ai/","section":"Posts","summary":"OpenAI\u0026rsquo;s $6.4B acquisition of Jony Ive’s WithLove merges minimalist design with AI surveillance capitalism. A masterclass in enshittification.","title":"On Designifying AI","type":"posts"},{"content":"","date":"23 May 2025","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"23 May 2025","externalUrl":null,"permalink":"/tags/rambling/","section":"Tags","summary":"","title":"Rambling","type":"tags"},{"content":"","date":"23 May 2025","externalUrl":null,"permalink":"/tags/strategy/","section":"Tags","summary":"","title":"Strategy","type":"tags"},{"content":"","date":"23 May 2025","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"25 April 2025","externalUrl":null,"permalink":"/tags/innovation/","section":"Tags","summary":"","title":"Innovation","type":"tags"},{"content":"I don’t have to remind you of the recent wave of protectionist policies sweeping across the United States, nor that these policies mark a significant shift in America’s economic approach. With President Trump’s “Liberation Day” (groan), we’re witnessing what is shaping up to be the most dramatic restructuring of global trade relations in decades - at least, in the medium to long term. Ok, now, I\u0026rsquo;ll stop with the hyperbole.\nI will try to keep my sardonic comments to myself for the most part. Also, I won’t be commenting on politics. I’m more interested in the weaving and fraying of macroeconomics and strategy. Specifically, I’d like to talk about means of production, innovation (what does it even mean?) and local growth.\nOne of the great ironies of liberal economic policy is what anthropologist David Graeber called “the iron law of liberalism”: any market reform or government initiative intended to reduce red tape and promote market forces will ultimately increase the total number of regulations, paperwork, and bureaucrats. Graeber presents plenty of examples from modern economic history to support his thesis - read the essay; it’s excellent.\nTL;DR: The (often unchallenged) narrative suggests that markets emerged as autonomous domains of freedom, independent from and opposed to state authorities. However, the historical reality is quite different. Markets have typically been either a side effect of government operations (especially military ones) or were directly created by government policy. English liberalism, far from reducing state bureaucracy, led to “an endlessly ballooning array of legal clerks, registrars, inspectors, notaries, and police officials who made the liberal dream of a world of free contract between autonomous individuals possible”.\nNow, relevantly to my argument here, Graeber went a step further by pointing out that (bureaucratic)\nCapitalism has become some kind of purely reactionary force, holding back technological development. What happened to flying cars? To space travel? Today universities, heavily bureaucratised, are unable to welcome the kind of eccentric people you need to truly innovate.\nUniversities aren’t the only ones at fault here. As Dr Max Gammon stated1, in\na bureaucratic system […] increase in expenditure will be matched by fall in production […] Such systems will act rather like ‘black holes,’ in the economic universe, simultaneously sucking in resources, and shrinking in terms of ‘emitted’ production.\nIn other words, the proliferation of bureaucracy is not simply the product of individual empire-building but is inherent in the system itself. Bureaucrats can convincingly defend almost every bureaucratic procedure as ‘essential to the working of the system’ (especially if we’re willing to ignore the tautology and conflict of interest in this sentence).\nYet attempts to modify or eliminate procedures typically add to the overall bureaucratic weight of the organisation - some sort of everyday, grotesque hydra where if you cut off one head, two will grow in its place.\nLooping back to Graeber, this bureaucratic displacement has contributed to what he called “bullshit jobs” - forms of employment that even those holding the jobs feel should not exist.\nBy slapping (obscenely arbitrary) tariffs on imported machinery and components, the state effectively tells domestic firms that they can only play in their backyard. This amounts to a blunt but (potentially corrective) nudge back towards localised bricolage.\nInstead of clicking “Buy Now” on a global supply-chain marketplace, designers, engineers, and tinkerers could be dusting off their machine shops, pooling resources, and lathes could be popping up in places that haven’t seen one since everything was deliberatively sent off to be built somewhere else (often in exploitative ways).\nAt first blush, this looks like classic mercantilism redux - state protectionism brazenly manoeuvring for balance-of-payments advantage. Yet, if you squint at the geopolitical map, you’ll see something subtler: an enforced hiatus on cheap imports creates a breathing space where local ecosystems can diversify their capabilities. Don’t get me wrong, if it walks like a duck and quacks like a duck, it’s probably a duck. But I choose to see the potential upside.\nRecall Dr Gammon’s observation of the NHS: more bodies, diminishing returns. The same applies to the monolithic R\u0026amp;D behemoths that have swallowed up public funding and university spin-outs. Local (or even, dare I say, decentralised) growth, by contrast, empowers a fractal notion of production - one where success does not equate to (global) scale.\nAnd, lest I sound like I’ve sketched out the blueprint for a gleaming new Detroit of decentralised fab labs without so much as checking the wiring, let me confess that this is very much a first draft of an idea. Well, not really, but this is the first time I made a public post about it.\nI haven’t yet mapped the precise mechanics of how a network of local innovation ateliers might interlock - from governance models to tooling standards - any more than I’ve solved the fact that much of the world’s machine-tooling, let alone microchips, never lived on American or European soil. Even “Made in Britain” widgets routinely lean on components sourced from Shenzhen or Penang. I’m not proposing we hurl ourselves back into the protectionist dark ages and rebuild vacuum tubes from scratch; rather, the challenge is to rethink the horrendously skewed equilibrium - one where we selectively nurture place-based capacity without pretending we can flick a tariff switch and instantly reconstitute entire industrial value chains overnight.\nPipe dream? Perhaps. I’ve been thinking a lot about this for the last few years, going as far as spending some of my precious annual leave a couple of years back discussing these very notions with John Thackara and a cohort of brilliant thinkers during one of his Summer events. Do you have something to add to the conversation? Please get in touch, I’d love to chat.\nDr Gammon was a British physician who studied the NHS between 1965 and 1973, where he noted that even if ‘inputs’ (i.e., number of staff) went up by 51%, ‘outputs’ (i.e., number of daily occupied beds) only rose by 11%.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"25 April 2025","externalUrl":null,"permalink":"/posts/on-the-paradox-of-protectionism/","section":"Posts","summary":"Could blitzkrieg protectionism somehow offer a (tentative) scaffolding for local growth?","title":"On The Paradox of Protectionism","type":"posts"},{"content":"\rAbout Me #\rI’m an experienced strategist, researcher and designer with a unique blend of quantitative skills, creativity, and coding capabilities. My background spanning academia, think tanks and corporate roles equipped me with expertise in design methods, cutting-edge technologies such as AI, Web3, and XR, as well as business development, including future market sizing, org design and internal capability building.\nWork Experience #\rSenior Consultant, Foresight \u0026amp; Portfolio Management - Connected Places Catapult #\rMarch 2024 – Current\nResponsible for developing the Human Connected Design Directorate’s strategy and foresight offering. I focus on three elements of strategy for our clients: where to play, how to win and how to be agile when change is necessary. I lead several bids and work packs.\nRepresentative Projects\nNational Critical Infrastructure: managed 50+ technologists and academics to deliver policy documents on how to secure critical infrastructure (i.e., highways, airports and ports) from adversarial cyberattacks. Rail Industry: oversaw the strategy and funding allocation of the R\u0026amp;D pipeline for the next control period (i.e., 5 years). International Airport: developed a digital twin simulation to demonstrate how and why the airport operations would change when transitioning to their decarbonisation agenda. Foresight Strategist - Dive Without Fear #\rOctober 2022 – March 2024\nFounding team member to establish, develop and commercialise a new foresights strategy offer. Directly responsible for developing novel computational simulations and new market measurement and evaluation frameworks for future markets. Co-developed speculative designs to immerse clients into alternative futures.\nRepresentative Projects\nGlobal drinks brand: 2030 valuations for five alternative futures to support the global marketing function in securing innovation and activation funding for new product development pipeline. Global consumers product company: development of the global marketing foresights team toolkit, including methodology development, capability design and org design. Global gaming company: developed a unique strategic foresight programme to identify and evaluate future markets, built computational simulations, and decoded three emerging markets, including market capitalisation benefits. Speculative Designer - Connected Places Catapult #\rJanuary 2022 – October 2022\nI helped establish design-led strategic foresight, work¬ing with the UK government, SMEs and academia to enable breakthrough innovation. I worked with private and public organisations spanning industries of advanced air mobility, rail, maritime transport, and digital twins. I was responsible for future product develop¬ment, horizon scanning, and prototyping. Further, I led design futures and client alignment workshops.\nLecturer - Ravensbourne University #\rSeptember 2020 – May 2022\nDesigned and delivered: Introduction to 3D Skills and Immersive Technologies - Coding, Figures and Visuals - Creative Computing - Digital Marketing.\nVisiting Lecturer - Royal College of Art #\rOctober 2018 – October 2022\nDelivered courses on ethics, future forecasting, trans¬disciplinary practices between design and science.\nMultiple Roles #\r2018 – Current\nAt the Near Future Laboratory, I am leading the design, development, and prototyping of a modern reinterpretation of the Casio F91W watch and handled hardware design for large-scale manufacturing. At Metalabel, I contributed to Web3 business development by building a distributed network of peers and developing custom ERC721-based tokens. For OPPO, I developed next-generation bone-conducting headphones, focusing on concept development, rapid prototyping, and patent applications. At CERN IdeaSquare, I supported the development of an open-source muon particle detector for earthquake early alert systems. At Cambridge University, I developed an AI-enabled sensor for real-time monitoring of insect infestations using sub-hearing oscillations. Skills #\rStrategy Corporate Foresight Product Development Rapid Prototyping Wireframing C++/C# Adobe Creative Suite Education #\rPhD, Robotics - Royal College of Art\nMA, Service Design - Royal College of Art\nBSc, Communication Design - Politecnico di Milano\n","date":"2 April 2025","externalUrl":null,"permalink":"/about/","section":"Filippo Sanzeni","summary":"About Me","title":"About Me","type":"page"},{"content":"","date":"16 February 2025","externalUrl":null,"permalink":"/tags/change-management/","section":"Tags","summary":"","title":"Change Management","type":"tags"},{"content":"When people casually toss around the term “wicked problem,” they’re not always talking about something insurmountable - just something messy and convoluted. I am guilty of doing this, too. In one of my (many) PhD drafts (you can read the final document here), I was trying to frame the problem of enhancement technologies as a wicked problem. I wasn’t completely crazy, as there is a rich history of design and wicked problems (see as an intro to the subject matter the excellent paper by Buchanan in 1992 and the more recent work by the consistently excellent Ben Sweeting). My supervisor1 quickly steered me away from that idea, as he noted that wicked problems are pretty well established in the academic literature and have ten well-defined characteristics.\nBut let me backtrack for a second. We can broadly classify problems as tame or wicked. In our everyday parlance, a “tame” problem is like a spreadsheet (or a neat computation problem requiring an efficient algorithm): clear-cut, neatly boxed in, and with a best-practice solution you can copy-paste at best or infer at worst from yesterday. Wicked problems, on the other hand, have no definitive outline or natural break point, and any “solution” you come up with isn’t a magic bullet - it’s just an incremental (or marginal) improvement.\nNow, don’t get me wrong. The phrase “wicked problem” has a legitimate pedigree in (amongst others) planning and design research. But there are ten traits originally set out to mark what makes a problem truly wicked. Here’s a quick rundown (trying to shy away from the academic lingo - but here is the OG paper if you’d like to read the real deal):\nNo Definitive Formulation: Wicked problems aren’t ever really nailed down. One day, it’s one thing; the next day, who knows, but definitely different. No Stopping Rule: Unlike a tidy to-do list on the ever-present post-it, there’s never a moment when you can declare, “Done!” The work just goes on, endlessly becoming2. Solutions Are Not True or False, But Better or Worse: There’s no neat binary here. You can’t say a solution is right; you can only say it’s less wrong than the alternatives. In other words, you can only aim for the best solution for the time being with the tools you have at your disposal. No Immediate or Ultimate Test: You can’t quickly run a diagnostics test on a wicked problem - the ripples caused by addressing a wicked problem take time to manifest, and usually, there are unintended consequences. Every Solution is a One-Shot Operation: There’s no sandbox mode here. Every fix has irreversible side effects, so you better be sure before sending it. No Enumerable Set of Potential Solutions: There’s no checklist of options you can pull out of a hat. The possibilities are vast, messy, and often hidden. Every Wicked Problem is Essentially Unique: Forget about one-size-fits-all; each wicked problem is its own beast, with a mix of context, people, and history that defies easy replication. Every Wicked Problem is a Symptom of Another Problem: These issues aren’t isolated bugs - they’re often the glitch in a much bigger, broken system. Multiple Explanations for the Discrepancy: Different people see different causes for the same mess, which only muddies the waters further. The Planner Has No Right to Be Wrong: In wicked problems, there’s no “oops, my bad” option - mistakes can (and often do) have far-reaching consequences. In my academic and professional experience, I often see folks conflating “messy” with “wicked”. Sure, many challenges are messy, but a problem is wicked only when it meets all ten defining conditions. I’m not suggesting anyone is disingenuous, but I argue that casually using the “wicked” label on every complicated issue does a disservice to our practice. When we overuse the term, we risk muddying our analysis and misdirecting our efforts - or often excusing choices on “oh well, it’s a wicked problem, so I couldn’t really know the implications of my design/strategy/policy decision”.\nHere’s where it gets interesting. Recent critiques (Turnbull and Hoppe, 2018, among others) have pointed out that slapping the label “wicked” on every complicated problem does more harm than good. It’s like calling every error in your code a “bug” without ever debugging - over time, the word loses its punch. Instead of treating problems as either fully wicked or entirely tame, we should see them on a spectrum.\nSome issues are wicked in a couple of ways, but not in every respect. They might be complex, sure, but maybe they’re not entirely unfixable. The trick3 is to identify which aspects of a problem are truly unruly - whether it’s uncertainty, conflicting stakeholder interests, or irreversible consequences - and then tailor your approach accordingly. Instead of thinking, “This is a wicked problem, so let’s pray and spray solutions”, we need to ask, “What part of this mess can we improve, even if just a little?”\nThis isn’t just academic navel-gazing. By peeling back the layers and pinpointing where the real nastiness lies, we free ourselves from the all-or-nothing mindset that so often paralyses action. In doing so, we not only gain clarity about what we’re dealing with but also carve out a path toward pragmatic interventions that, cumulatively, can shift the balance. Acknowledging the spectrum of wickedness isn’t about copping out. It’s a rallying cry for a more honest practice.\nMy own PhD practice hugely benefitted from not framing my subject matter as a wicked problem. It forced me to really dissect it and figure out the intervention points and how to build a (practice-based) approach to designing wearable enhancement technology. It’s definitely not perfect, but it did lead me to several “contributions to knowledge” 4 that led me to add three letters after my name.\nThank you, Stephen Boyd Davis, for picking up the pieces of my work and guiding me to a cohesive thesis. I’ve said this many times, but this is the first time I write it black on white on a webpage: Stephen is one of the most caring, intellectually thorough and refreshingly straight-shooting supervisors you could ever have. I am lucky.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nOk, I lied. Slight academic detour if you’re interested in the meaning of “becoming”. Spoiler: it is rooted in the French philosopher Guttari’s work, influenced and expanded by many critical feminist scholars.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWell, it’s not really a trick. More of professional and intellectual honesty, but I digress.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nContribution to new knowledge is the original addition to, or refinement of, the existing body of academic understanding within a particular field. In simpler terms, it’s what you bring to the table that others haven’t already put there - a fresh insight, a new theory, or a novel method that moves the conversation forward.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"16 February 2025","externalUrl":null,"permalink":"/posts/on-overusing-wicked-problems/","section":"Posts","summary":"I\u0026rsquo;ve got an itch to scratch regarding wicked problems and how often they can be an excuse for inaction","title":"On Overusing Wicked Problems","type":"posts"},{"content":"","date":"12 February 2025","externalUrl":null,"permalink":"/tags/genai/","section":"Tags","summary":"","title":"GenAI","type":"tags"},{"content":"\rThe Context #\rMeta torrented 81.7 terabytes of pirated books from shadow libraries like Z-Library, LibGen, and Anna’s Archive to train its AI models like LLaMA. This wasn’t a one-off - court documents reveal Meta previously downloaded another 80.6TB from LibGen alone. To put this in perspective, that’s equivalent to approximately 45e+10 (that reads as more than forty-five billion) pages of scanned books1.\nBut Meta, besides riding the 777 seas, didn’t just download - they actively concealed their tracks. Employees avoided using company servers, switched to VPNs, and joked about the illegality. One engineer wrote, “Torrenting from a corporate laptop doesn’t feel right”, while others debated ethics, comparing LibGen to The Pirate Bay. Even CEO Mark Zuckerberg was implicated: internal emails show the decision to use pirated data was escalated to him, contradicting his public denials.\nI know that the reference to those \u0026lsquo;777 seas\u0026rsquo; is obscure at best, so here\u0026rsquo;s the reference. Razor 1911\u0026rsquo;s work on cracktros is some of the finest put there. And this tune is straight up bangin.\nInternet Archive vs. Meta’s Corporate Piracy #\rThis news (scandal?) highlights the hypocrisy in how copyright laws are enforced. The Internet Archive, a nonprofit digital library, has faced relentless lawsuits for lending scanned books under controlled “digital borrowing” models. Publishers like Hachette, HarperCollins, Wiley, and Penguin Random House sued it for “mass copyright infringement,” arguing that even limited lending harms sales. Yet Meta - a trillion-dollar corporation - downloaded terabytes of pirated content with near-impunity, adding insult to injury by masking its actions to avoid accountability. Irony? More like corporate kleptocracy.\nThe Archive’s crime? Letting you “borrow” a PDF like it’s 1989. Meta’s crime? Swiping literal billions of pages to feed the AI machine that spits out derivative slop, threatening the same writers whose work it regurgitated. The takeaway, ça va sans le dire, is that if you’re a trillion-dollar company, piracy isn’t theft - it’s R\u0026amp;D. If you’re a grad student downloading a textbook? Straight to copyright jail.\nPirate a book? Straight to jail.\rMeta’s internal communications read like a dark comedy. Employees debated ethics while torrenting, with one researcher calling it “beyond our ethical threshold”. Yet they proceeded, operating in so-called stealth mode to avoid detection. The company even messed with their Torrent client settings to avoid seeding, ensuring they wouldn’t redistribute content - making them not just pirates, but leeches. In Torrent parlance, that’s like taking the last slice of pizza and ghosting the chat. For a company built on “community”, their P2P etiquette is worse than a live-action adaptation of an anime2.\nLeechers in Suits and the Hypocrisy Machine #\rMeta’s actions are part of a broader trend. OpenAI, Nvidia, StabilityAI and others face lawsuits for training AI on copyrighted works (see here for an up-to-date tracker of all the lawsuits happening at the moment). The stakes are - to the risk of sounding bombastic - existential for writers: AI models trained on pirated books can churn out derivative stories, obviously endangering livelihoods with machine-generated slop.\nWorse, AI could enable corporations to bypass human creators entirely. Imagine studios using AI to generate entire fictional universes - à la Harry Potter or Bionicle - then monetising toys, films, and merch without paying a single author. Yes, this is speculation, as a judge dismissed claims on risks of future damage to intellectual property as too speculative. Yet, I argue this future isn\u0026rsquo;t too far away or inconceivable.\nI\u0026rsquo;m not trying to crystallise the debate into a binary good/evil. The underlying issue is, well, complicated: who gets to profit from humanity’s collective knowledge? Shadow libraries like LibGen emerged to bypass paywalls and democratise access to knowledge, but Meta (and I\u0026rsquo;m pretty sure all the other GenAI companies) co-opted them for corporate gain.\nLLMs and [checks script] Innovation? #\rLet’s cut the techno-optimist crap. AI trained on pirated books is copyright sleight-of-hand. As a side effect, writers aren’t just competing with AI, they’re competing with their own pirated words. Romance novels (18% of adult fiction sales) are low-hanging fruit for algorithms3, but even academic papers aren’t safe.\nImagine a future where Elsevier charges $29 (or more) for a paper written by a bot trained on pirated research. Oh wait, that’s already happened.\nChokepoint Capitalism and Fighting Back #\rMeta’s piracy spree is a masterclass in chokepoint capitalism. For the uninitiated, chokepoint capitalism is the art of monopolising markets by controlling critical bottlenecks, squeezing workers and creators dry while hoarding profits (I din\u0026rsquo;t invent the term, Giblin and Doctorow did. Their book is well worth a read). Think Amazon strangling book publishing, Spotify finessing musicians, or Live Nation monopolising concert venues.\nMeta’s playbook is classic chokepoint strategy:\nLock in the supply by filling your digital coffers with scraped data in an effort to monopolise training data for AI models. Eliminate competition by arguing that scraping copyrighted works is “fair use,” a legal loophole smaller players can’t afford to exploit4. Extract value by getting paid for a service you built on others\u0026rsquo; work, all while Zuckerberg schmoozes with politicians to keep regulators at bay. The real crime here isn\u0026rsquo;t Meta doing it - but if they got away with it. But there is hope. The Internet Archive still fights. Authors are suing. We must demand radical transparency from AI companies, insisting they disclose the precise sources of their training data instead of hiding behind “fair use” hand-waving. At the same time, writers, coders, and creatives need to unite - whether through forming unions or coordinating collective legal action - to secure fair licensing deals or to challenge corporate overreach by suing en masse. And finally, we must decentralise control by supporting independent libraries, not as piracy hubs, but as antidotes to corporate domination.\nThis work licensed under CC BY 4.0. Pirate responsibly.\nThis is calculated as an average of 2kb per page of text - corresponding to about 500 words (if ASCII-encoded. The difference with UTF-8 should be minimal)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nI still shudder thinking about that adaptation of Dragon Ball.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nBut how much money are we talking about here, really, I hear you cry from the back of the room. You\u0026rsquo;d be surprised to learn (at least, I was) that (18% of the global fiction market corresponds to roughly $2 billion)[https://www.thebusinessresearchcompany.com/report/fiction-books-global-market-report].\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFor a very thorough read on the subject, I cannot recommend Sobel\u0026rsquo;s article Artificial Intelligence\u0026rsquo;s Fair Use Crisis. Just to note, this essay was published in 2017, the same year in which Google\u0026rsquo;s Attention is All You Need, the paper that introduced Transformers - the architecture that enables virtually all modern GenAI systems - came out. People have been shouting about the very issues I discuss here for a very long time.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"12 February 2025","externalUrl":null,"permalink":"/posts/on-piracy-for-me-not-for-thee/","section":"Posts","summary":"LLMs, institutionalised piracy and other good things all add up to slop. Let\u0026rsquo;s dissect Meta\u0026rsquo;s latest blunder.","title":"On \"Piracy for Me, not for Thee\"","type":"posts"},{"content":"\rIntroduction #\rI’ve been toiling on this post for what feels like ages - mainly driven by my admiration for Bunnie Huang’s subversive exploits in the hacking world — when, suddenly, the universe threw me (well, us all) a curveball. Just as I was about to settle into a rhythm of contemplative critique, the latest political and technological snafus burst onto the scene. DeepSeek, that Chinese AI startup / trading firm, emerged from the depths with understated swagger (see Reuters and NY Post), while on the other side of the world, the tariff situation / war rolled in with all the subtlety of a sledgehammer (see also (my previous post)).\nAs the West entrenches its intellectual property and the East chuckles at the absurdity of it all, I couldn’t help but get swept up in this global dance of ideologies and economics. So, here we are: a deep dive into the myths of founders and the contrasting philosophies of IP. Enjoy the show.\nThe “Heroic Founder” Narrative #\rIn the West, the founder is cast as the Prometheus of commerce, a solitary figure who dares to steal fire from the gods of mediocrity and gift it to humanity as the next billion-dollar innovation. This myth, popularised by Silicon Valley’s self-congratulatory folklore, pervades every aspect of how businesses are built, marketed, and celebrated. From garage startups to IPO stardom, founders are imagined as singular geniuses, their success a reflection of personal brilliance rather than the intricate web of societal, technological, and historical forces that converge around them.\nBut myths are not just stories we tell – they are stories that shape us. The “heroic founder” narrative is no exception. It is a lens, warped by Western ideals of individualism, that blinds us to other ways of seeing. It insists that the value of an idea lies in its ownership, that the act of creation is the triumph of one over many. And it assumes that success is earned only through dominion over markets, competition, and, crucially, intellectual property.\nThis is the myth that tells you Steve Jobs invented the smartphone, that Elon Musk’s name alone propelled humanity closer to Mars, that Jeff Bezos brought the age of logistics into being from sheer willpower1. It is a story as intoxicating as it is dangerous, because it reduces the complex, collaborative act of innovation to a singular narrative of conquest. It forgets that Apple’s iconic devices are the fruits of a global supply chain, that Tesla’s rise depended on open patents, or that Amazon’s dominance was paved with taxpayer-funded infrastructure.\nThe heroic founder becomes not just a role model but a justification for systemic inequities, where those who succeed are given all the credit and those who fail are left to bear all the blame. This is not to say that founders don’t matter – but how we valorise them obscures the collective work of invention, the shared nature of knowledge, and the cultural contexts shaping success.\nMy thesis is relatively straightforward. The founders are not lone heroes; they are actors on a stage built by many hands. And the first principle of strategy, especially across cultures, is to see the stage – not just the spotlight.\nIP as a Sacred Pillar of Innovation #\rIn the West, IP is not just a legal framework but an article of faith. It promises that ephemeral, fragile, and fleeting ideas can be bound, commodified, and protected (from whom, you might add). The prevailing belief is that innovation must be safeguarded like treasure, that the free market rewards those who stake their claim, and that IP laws are the tools that make this possible. In this frame of mind, copyrights, patents, and trademarks are akin to the engines of progress, the invisible machinery that ensures the wheels of invention turn toward profit.\nThis narrative assumes that innovation is a zero-sum game: for one to succeed, another must fail, and for one to profit, others must be excluded. The fortress of IP becomes a weaponised space, not a shared foundation. It is no accident that some of the largest companies in the West wield their patents like swords, cutting down competitors and raising barriers to entry (please excuse the war-infused language; it’s the most used in this case. Whenever someone mentions a moat, I chuckle, thinking of medieval castles and suits of armour. But it is what it is, for better or worse).\nThis framing ignores the reality that most ideas are recombinant, as much a product of collaboration and iteration as of individual genius. The smartphone is a perfect case in point. Its DNA is not wholly owned by any single entity but a tangled lineage of technologies: touchscreen interfaces, lithium-ion batteries, global positioning systems, and wireless communication protocols. Each innovation is the product of decades of collective work, much of it funded by governments (i.e., the military goliath), universities, and open research communities.\nTo treat IP as sacred is to turn a blind eye to this truth. It is to enshrine ownership over sharing, hoarding over collaboration. And yet, this narrative persists. It persists because it serves the story of the heroic founder, the lone innovator who triumphs by building a fortress around their idea. It persists because it aligns with Western values of individualism and capitalism, where property – land, goods, or knowledge – is the ultimate measure of success.\nBut this myth unravels in the face of global realities. In Shenzhen, where the shanzhai ethos thrives, IP is treated not as sacred but as a starting point. Designs are shared, iterated upon, and improved in an ecosystem that prizes speed and adaptability over exclusivity. This collaborative chaos has birthed some of the most rapid technological advances in recent history.\nFor founders seeking to operate in cultures beyond the West, the sanctity of IP must be questioned. The first principle is to see IP not as a universal truth but as a cultural construct that can be reimagined in the service of collective progress. The real innovation, then, lies not in defending ideas but in letting them grow where they will.\nThe Shanzhai Ethos #\rIf the West’s vision of innovation is a fortress, Shenzhen’s is a bustling bazaar. In this sprawling city, ideas spill into the streets, tumble through factory doors, and cross invisible boundaries, weaving and fraying as they go.\n“Shanzhai” is often translated as “copycat,” but to stop at that definition is to misunderstand its spirit entirely. Yes, shanzhai often begins with imitation, but it does not end there. It is a process of building upon what already exists, of taking an idea and reimagining it through collaboration and competition. A smartphone design might pass through dozens of factories in a matter of weeks, each one tweaking the hardware, refining the software, or reducing the cost. What emerges is not a copy but a kaleidoscope of possibilities, each iteration optimised for a specific market or niche.\nBunnie Huang often speaks of this phenomenon as an alternative to the West’s rigid IP-driven model. He describes the design dialogues that occur in Shenzhen’s marketplaces, where components and ideas are exchanged as fluidly as wrinkled tenners (damn you, modern and wrinkle-free banknotes). In this ecosystem, speed and accessibility trump exclusivity. A new feature can appear in a prototype on Monday and hit production by Friday – a timeline that would be unthinkable in the West.\nIn Shenzhen, no single inventor stands at the centre of the story. Instead, innovation is a communal act, a dance between countless players: the engineer designing a circuit board, the factory worker suggesting a process improvement, the distributor identifying an untapped market. Each contributes to a whole that is greater than the sum of its parts.\nOf course, this openness comes with trade-offs. Quality control can be inconsistent (or sometimes completely missing), and the lack of formal IP enforcement means that the original creators often see little financial reward. But these challenges are offset by the sheer dynamism of the system. Shenzhen has become the global epicentre of electronics not in spite of shanzhai but because of it. To dismiss shanzhai as mere piracy is to miss the point entirely. It is not a rejection of innovation but a different lens to approach it.\nDebunking the “Copycat” Myth #\rTo outsiders, Shenzhen’s manufacturing ecosystem often appears as an intellectual free-for-all: a place where designs are copied wholesale, patents are ignored, and original thought seemingly drowns in a sea of imitation. This perception fuels the myth that Shenzhen is nothing more than a factory for knockoffs, a chaotic hub of low-cost replication. But like most myths, this narrative reveals more about the biases of its storytellers than the truth of the system it seeks to describe.\nGoing back to Bunnie Huang, he is quick to dismantle this caricature. He sees not a sea of mimicry but a landscape of fearless (perhaps sometimes unhinged) innovation. Shenzhen\u0026rsquo;s so-called “copycats” are, in reality, designers, engineers, and manufacturers operating at a pace and scale unmatched anywhere else in the world. They do not simply reproduce – they iterate, modify, and optimise, often in ways that push technology forward in directions its original creators never envisioned.\nTake, for instance, the meteoric rise of the smartphone in Shenzhen. While companies like Apple and Samsung were busy litigating over design patents, Shenzhen’s ecosystem was churning out affordable, feature-rich devices tailored to specific markets. These devices weren’t just clones – they were adaptive solutions. Some stripped down features to lower costs, while others experimented with new hardware configurations. The result was a dizzying array of products, from rugged phones for construction workers to models with high-capacity batteries for regions with unreliable electricity.\nThe “copycat” myth also overlooks the collaborative ethos that underpins this system. In Shenzhen’s markets, engineers and designers trade ideas as openly as they trade components. Factories share process improvements with their peers, not out of altruism but because collaboration ensures mutual survival in a hyper-competitive environment. This is not theft—it is the communal forging of progress.\nThe “copycat” label is particularly pernicious because it imposes Western assumptions about IP onto a system that operates on entirely different principles. In the West, originality is fetishised, and the worth of an idea is measured by its exclusivity. In Shenzhen, the worth of an idea lies in its adaptability and impact. An innovation that is shared, replicated, and improved is far more valuable than one that is locked away behind legal barriers.\nThe real myth, then, is not that Shenzhen is a land of copycats but that copying is the enemy of innovation. In truth, copying is where innovation often begins. The spark lights the fire, the first step in a journey that leads to something entirely new. The question for strategists is not how to stop copying but how to harness its power to create something greater (steal like an artist, anyone?).\nReady, Set,… Fight? #\rAt first glance, the East and West innovation paradigms seem irreconcilable. Yes, while the two systems are different, but they are not necessarily incompatible. They merely represent two ends of a spectrum. The West’s emphasis on exclusivity and long-term R\u0026amp;D provides stability, while the East’s openness fuels rapid iteration and accessibility. The challenge is not choosing between these models but finding ways to bridge them or ‘code switch’ between them on a case-by-case basis.\nSuch a synthesis would require shifts on both sides. The West must loosen its grip on the idea that IP is sacrosanct, recognising that openness can drive innovation in ways exclusivity cannot. This might mean embracing more flexible licensing models or adopting collaborative approaches to R\u0026amp;D, as seen in the open-source software movement. The East, meanwhile, must address the systemic issues that arise from a lack of IP enforcement, particularly the challenges of incentivising original innovation and ensuring creators are fairly compensated.\nDon’t take it from me: there is no empirical evidence to support the myth that patents increase innovation or productivity. Also, as quite eloquently put by Fernandez, Puel and Renaud in 2016:\nthe Californian innovation model that underpinned the development of the Internet and the Shenzhen innovation model in the hardware field cannot be applied or reproduced elsewhere, for they are intrinsically bound to the territories in which they emerged.\nSo, how can we work in both frameworks, alternating between the two depending on the situation? And where is Europe and the UK in all of this? Please reach out if you have any thoughts, I’d love to hear from you.\nIn fact, this is simply not true, as seen here too.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"7 February 2025","externalUrl":null,"permalink":"/posts/on-the-innovator-myth/","section":"Posts","summary":"A deep dive, spurred by recent events (Deepseek, wink wink), on the different mental frameworks of innovation between the West and East. Yes, I\u0026rsquo;m simplifying.","title":"On The Innovator Myth","type":"posts"},{"content":"","date":"3 February 2025","externalUrl":null,"permalink":"/tags/hardware/","section":"Tags","summary":"","title":"Hardware","type":"tags"},{"content":"I’ve been designing a breakout board for a Bluetooth 5.4 module (see FSC-BT1038B project). On the surface, it’s a straightforward PCB - a handful of components soldered onto a green slab of fibreglass (or black\u0026hellip; I still haven’t settled on the silkscreen colour. But I digress). Yet its creation spans continents: KiCad, an open-source tool built by a global community; a PCB fabricated in China on (probably) German machinery; capacitors from South Korea; resistors from Taiwan; and a Bluetooth module designed and likely manufactured in China. Like most (I’d even wager to say all) modern electronics, this little side project is a testament to globalisation’s efficiency - and its fragility once you scratch the surface.\nTariffs are back in vogue, championed by policymakers nostalgic for America’s 19th-century industrial rise. From Alexander Hamilton’s Report on Manufactures to the 40% average tariffs of the 1800s, the U.S. wielded protectionism to shield trailing industries, fund government coffers, and avoid income taxes. By 1910, tariffs accounted for around 2.5% of the USA’s GDP. But this strategy had trade-offs: Southern agrarian states suffered under retaliatory European tariffs. Foreshadowing, anyone?\nFast-forward to 2025. The world has unimaginably changed. My $2 PCB relies on hyper-specialised global supply chains. A Chinese factory can produce it cheaper than a local shop, and a tariff on imported boards might push my project’s cost beyond feasibility on my hobbyist budget. Yet proponents argue tariffs could revive U.S. manufacturing (and I’m sure many people are vying to propose the same this side of the pond). The rhetorical question is: Can 19th-century logic work in a world of smartphones and always-on, cloud-shackled devices?*\nRecent history offers clues. In 2018, the U.S. imposed a 20-50% tariff on washing machines. The result? Prices rose - not just for washers, but for dryers, too 1. Consumers bore a $1.5 billion annual cost, while only 1,800 jobs were created - breaking it down, each new job ended up costing around $815,000. Similarly, steel tariffs in 2018 boosted domestic steel employment but cost more jobs in industries reliant on steel, like automotive and construction. Tariffs became a stealth tax, redistributing wealth from consumers to protected sectors, often failing to reshore production.\nBut not all tariffs fail. The 1964 Chicken Tax - a 25% tariff on light trucks - propelled Detroit’s dominance in SUVs and pickups. Foreign automakers like Toyota and BMW skirted the tariff by building U.S. plants and creating jobs. Yet this “success” came at a cost: less competition, higher prices, and slower innovation. Protectionism worked - but only because the government tolerated oligopolies2.\nToday’s policymakers face a paradox. Tariffs could, in theory, support strategic industries like semiconductors or green energy. Reliance on geopolitical rivals for critical goods is risky, as COVID-era chip shortages proved. But reshoring isn’t simple. My Bluetooth module depends on rare earth metals mined in China, refined in Malaysia, and assembled in Vietnam. A tariff here might not revive U.S. mining; it could just reroute supply chains through Mexico or India.\nMoreover, modern products are too complex to untangle. A single iPhone contains parts from 43 countries as of 2018 - I couldn’t find more recent data. As the 2018 tariffs showed, companies often absorb costs or pivot to tariff-hopping workarounds (like Mercedes’ “flatpack” vans), rather than reshoring.\nMy $30 Bluetooth board exists because globalisation works. Yet I recognise the risks of overreliance - on foreign chips, on single suppliers, on politically (and morally) fragile chains. Tariffs can boost local growth, but only if applied with precision. Blanket tariffs, like those floated around these days, risk taxing innovation out of existence. The U.S. thrived in the 1800s by nurturing industries while investing in railroads, education, and R\u0026amp;D. Today, we need a similar vision: tariffs as a scalpel, not a sledgehammer.\nFor a riveting read on the subject (I promise!), check this 2020 paper\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nNot-so-flash-news: arguably, the US, and particularly the Biden Administration, started enforcing Antitrust laws.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"3 February 2025","externalUrl":null,"permalink":"/posts/on-tariffs-and-globalisation/","section":"Posts","summary":"Tariffs have been a useful tool for protectionism. Up the 1920s. Perhaps today things are a little more complicated.","title":"On Tariffs and Globalisation","type":"posts"},{"content":"Bambu Lab, a relatively recent darling of the 3D printing world, has joined the pantheon of tech companies adopting the tradition of hardware enshittification. Their latest move - a firmware update on January 16, 2025 - introduced “security measures” so unconvincing they might as well have come with air quotes and a side of contempt (I’ll be using air quotes liberally throughout this post, please do read them with irony). Ostensibly designed to “protect users”, the update added an authentication mechanism that smells suspiciously like nerfing capabilities that customers paid for.\nThe backlash was swift, as it always is when you poke a once-loyal, now-betrayed user community. The update sparked outrage over its potential to hobble third-party slicer software like the excellent OrcaSlicer. It left users wondering how long it would be before their shiny Bambu printers became cloud-dependent bricks. Enter Louis Rossman, YouTube’s consumer rights activist, who wielded righteous indignation to rally the troops. Faced with an angry mob, Bambu Lab scrambled to reassure everyone that their new “Bambu Connect” platform would still allow third-party software and offline operation - but you would still have to register to their online service to set up the printer. Also, most offline functionality is now locked behind an opt-in \u0026lsquo;Developer Mode\u0026rsquo;.\nI remember early discussions when their printers came to the market about their, let’s call them less than ideal tactics: their automatic filament changing add-on has RFID readers to ‘verify’ matching tags in first-party filament spools. Foreshadowing much? Anyways, that system has been reverse engineered too.\nWhen you crack open Bambu Lab\u0026rsquo;s AMS you\u0026rsquo;ll be pleasantly surprised to see RFID readers (the circle-shaped copper coils on either side) to match the tags in the filament spool. I can stretch my thinking and understand that this feature allows for automatic profile/settings switching in the slicer, but in this case it was simply a foreshadowing of what would come down the line.\rBambu Lab isn’t the first company to tread this path of undermining customer autonomy for a quick buck. It’s a cliche at this point: take a product that works perfectly fine, add unnecessary restrictions, call it “progress” or [insert corpo-speak here], and pray nobody notices.\nRemember when Apple unceremoniously ditched the headphone jack in 2016, insisting it was a brave leap forward? Sure, if by “brave”, they meant shoving millions of users into proprietary and absolutely unfixable (aka soon-to-be landfill) AirPods. Or take John Deere, which transformed tractors into DRM-riddled techno-prisons that farmers can’t repair without corporate blessing. Even Keurig introduced DRM on their coffee pods in 2014, trying to stop customers from using cheaper, white-labeled alternatives. Because nothing screams innovation like locking people out of their morning coffee.\nI don\u0026rsquo;t have much to add to this hilarious image.\rAnd let’s not forget the grand tragicomedy of printers - HP, Canon, Epson - who have all, at some point, decided that ink should cost more than blood. Firmware updates to block third-party cartridges? Check. Software that reports nonexistent maintenance issues to force you to buy replacements? Double check. It’s a masterclass in finding new ways to turn customers into hostages. 1\nAllow me a rant. Everything from cars to toasters is now “smart,” which really means “we can turn it off whenever we feel like it” or “we can change the ToS and basically brick your device remotely”. Tesla owners found this out the hard way when the company started charging to unlock features already physically built into their cars. Similarly, the unfortunate trend in consoles and other videogame hardware is to remove options for physical disks (looking at you, PlayStation 5 Digital Edition) or, more in general, physical media.\nThe folly of moves like Bambu Lab’s is that they target the wrong audience. Your average 3D printing enthusiast isn’t some casual consumer who bought a gadget on a whim - they’re professionals, DIYers, and tinkerers who chose your product because it empowered them to make things their way. These folks will void warranties without skipping a beat if it means improving functionality. They’re not just customers; they’re collaborators, evangelists, and, critically, the people who shape the narratives around your brand.\nThe same applies to farmers fighting John Deere’s repair lockdowns or prosumers who flocked to open-source platforms to escape the constraints of proprietary ecosystems (remember when Autodesk changed their licensing for Fusion360 and the exodus towards open-source alternatives?). These groups prize autonomy, transparency, and the ability to solve problems on their own terms. By locking down your ecosystem, you’re not offering security or innovation - you’re waving a red flag in the face of the very people who value your product for what it could be, not what you want to limit it to.\nAt the heart of enshittification is a paradox: companies implement these strategies to maximise profit, but they often erode the very customer loyalty that made them successful in the first place. What Bambu Lab (and its ilk) fail to grasp is that ecosystems feed on trust, not coercion. Definitely, issuing a semi-gaslighting press release was not the most tactically savvy thing to do.\nBut no. Like so many others, they chose the path of least imagination and greatest irritation. The result is a cautionary tale for folks working in strategy and a grim reminder for users: the products we love don’t belong to us - they belong to the companies who see us less as customers and more as an ongoing revenue stream.\nAlienating your customer base never ends up in meadows and rainbows. A bad move with tinkerers? They’ll reverse-engineer your hardware, fork your software, and post the workaround online before you’ve finished drafting your press release. Upset farmers? They’ll lobby lawmakers, file lawsuits, and spark a right-to-repair movement undermining your business model. Frustrate prosumers? They’ll flock to your competitors.\nBambu Lab’s botched update is a sad reminder of how not to engage with a technically-minded audience. They could have strengthened their market position and maintained their following if they had leaned into what their customers expect and bought the printer to begin with (wild concept, I know). Instead, they risk becoming just another name in the cautionary tales of enshittification.\nSo here’s to the next firmware update, the next subscription fee, and the next set of proprietary dongles. Enshittification marches on, one locked door at a time.\nOf course, clever people have devised ways to get around these artificial restrictions. Better yet, if I can offer modest advice, get yourself a laser printer that is a decade old - they’re built like tanks (albeit slower) and don’t have these silly DRMs.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"21 January 2025","externalUrl":null,"permalink":"/posts/on-hardware-enshittification/","section":"Posts","summary":"A notoriusly good 3D printer manufacturer decided to alienate their customer base py pushing unnecessarily restrictive firmware updates.","title":"On Hardware Enshittification","type":"posts"},{"content":"Over this winter break, I went down a bit of a rabbit hole, prompted by this excellent talk by Peter van Hardenberg on why we can’t avoid writing complex software (video embedded after the break). In the talk, Peter brings up something I never heard before: risk homeostasis. As a keen cybernetician and strategist, my spidey senses tingled – mainly because of the shame of never coming across the term. Allow me a couple of definitions and references:\nThe risk homeostasis theory posits, in essence, that a control mechanism analogous to the thermal homeostatic system in warm-blooded animals tends to keep risk per unit time constant, and, as a consequence, the number of traffic accidents per unit time of driving also tends to remain constant, essentially independent of changes in the traffic safety system. Reference. In essence, the theory holds that it is the target level of risk, rather than the absolute level of environmental risk, that determines accident loss. RHT therefore posits a population-level closed-loop process in which target and actual risk are compared. Reference. In other words (and going beyond the transport safety subject), risk homeostasis suggests that each of us has a personal threshold for how much risk we’re comfortable taking. When something shifts our perception of safety, we tend to adjust our behaviour to maintain a steady level of what we consider “acceptable risk.”\nNow, let’s talk about software. There’s this thing Peter calls “complexity homeostasis”. You start a new (obviously SaaS) product and ship it. Its codebase is neat and well-maintained. Then, you start adding features and teammates. At first, everything’s cool, but eventually, it becomes a tangled mess, and you refactor. So, you simplify things, and it feels great. But then, as you keep adding features or making changes, the complexity creeps back in, and you’re back where you started.\nIt’s like we have this internal threshold for how much complexity we’re willing to deal with. When things get too complicated, we take steps to simplify. But once it’s simple again, we don’t stop; we keep adding more until it gets complicated again.\nJust like with road safety and software development, it struck me that we might unconsciously maintain a certain level of complexity within organisations and in strategy. Organisations naturally accumulate layers of processes, policies, and teams as they scale. At first, this feels like progress – each new addition addresses a specific need or fills a perceived gap. But over time, communication slows, silos emerge, and decision-making becomes cumbersome, involving several decision-makers across the organisation.\nThat’s when leadership calls for a “reorg,” shedding layers of complexity to regain agility – like a phoenix, to burn it all down (yes, yes, metaphorically) to reemerge nimble. But just like in software, this simplification is rarely permanent. Freed from their previous constraints, organisations soon begin layering on new complexities, repeating the cycle.\nContrast that with strategy, where complexity homeostasis plays out more abstractly. A strategy (hopefully) starts as clean and focused – a vision, a goal, a clear path forward. Over time, though, as market conditions shift or new opportunities emerge, the strategy often accrues “add-ons”. New KPIs, adjacent goals, and tangential initiatives creep in. Before long, the strategic vision is muddied by competing priorities and internal politics.\nAt this point, companies might declare a strategy reset, reducing the clutter to refocus. The paradox is that while organisational design is constrained by structure and operations, strategy starts from ideas and intentions. Here, the risks of overcomplication are harder to detect.\nYou can see the bloated org chart or the sluggish workflows and identify them as symptoms of excess, whereas strategic complexity often hides in plain sight, cloaked in corpo-jargon and PowerPoint decks. A strategy might sound sophisticated because of its complexity, but in reality, it’s a word salad. That said, perhaps both domains share an underlying driver: our discomfort with simplicity. In organisations, there’s often an implicit belief that “more” equals progress – more teams, more processes, more sophistication. In strategy, the allure of complexity can come from wanting to appear thorough or future-proof. Yet, in both cases, complexity isn’t inherently bad; it becomes problematic when it’s unconscious, unmanaged, or left unsaid.\nWhen it comes to large companies, complexity isn’t just a side effect – it’s practically baked into the business model. After all, it takes a lot of people, processes, and politics to keep the corporate machine purring. But let’s get one thing straight: scale is not a virtue in itself. A big organisation isn’t inherently better; it’s just harder to steer. Yet somehow, we’ve arrived at a world where “how many employees we have” or “how many countries we operate in” is treated like a badge of honour. Spoiler alert: size alone isn’t a KPI - it’s a side effect. Outcomes and outputs should be the real focus, but they’re often buried under layers of quarterly reports.\nThink about it: we don’t applaud a city for having more traffic lights than its neighbour; we measure it by its liveability. Why, then, do we celebrate companies for their headcount instead of their impact? A sprawling org chart might look impressive on LinkedIn, but what’s the point if it takes three meetings, two approvals, and a ritual sacrifice to deploy a minor product update?\nThe irony is that large companies often mistake activity for effectiveness. They’re so busy managing the machinery of their size that they forget why they scaled in the first place: to deliver value. When was the last time you heard a customer say, “I love this brand because they’ve got so many regional VPs”? Exactly.\nComplexity in large organisations isn’t inherently evil but should serve a purpose. If complexity enables better outcomes – more resilient systems, faster innovation, broader impact – great. But more often than not, complexity serves complexity. Bureaucracy grows to support bureaucracy. Meetings beget meetings. Teams spring up to manage the mess created by other teams. And the worst part? We normalise it. Here’s a snarky reality check: if your company’s biggest competitive advantage is its ability to staff a project team with 40 people in three time zones, you’re not competing - you’re compensating. A nimble startup with 10 people and a clear mission can run circles around that kind of inertia (shameless plug for my previous post).\nThe solution isn’t to downsize for the sake of downsizing or to fetishise the startup mentality. It’s to refocus on what matters: outcomes and outputs. Ask yourself: What’s the minimum structure we need to achieve our goals? How can we avoid the gravitational pull of unnecessary complexity? And, most importantly, how do we keep [insert your goal here] at the centre of everything we do?\nAllow me to go back to the literature to conclude this ramble. Wilde’s RHT model (1988, proposition 2) outlines three paths to achieving this homeostasis: adjusting behaviours within the current environment, switching modes entirely (technically called mode migration), or outright avoidance.\nIn software, when systems become safer or simpler, we often “spend” that safety by layering on new features or risks until we hit our perceived threshold of complexity. Similarly, organisations toggle between adding structure and stripping it back, chasing a balance between agility and stability. And in strategy, we rub shoulders with complexity, only to periodically step back and reset when clarity is lost.\nWilde’s framework offers a compelling invitation to rethink this relationship with risk: it doesn’t remain an open wound; it scabs over and integrates into the fabric of our decisions. After the initial turbulence, systems - be they human or organisational - tend to stabilise.\nThe real danger in strategy isn’t risk itself; it’s inertia. Playing it safe often leads to stagnation, missed opportunities, and an organisational culture that fears failure more than it values innovation.\nConsider the behavioural adjustments Wilde mentions: when risk increases, we adapt. A driver in stormy weather might grip the wheel more tightly, lower their speed, or increase following distance. Similarly, a company exploring an adjacent market might acquire talent, test smaller initiatives, or build partnerships to reduce exposure (and, often, costs).\nAnd then there’s mode migration. In strategy, this could mean pivoting from one business model to another, adopting new or more efficient technologies, or reimagining how value is delivered. These shifts may feel radical, but they’re often the very moves that define a company’s longevity (think of Netflix pivoting from DVD rentals to streaming or Apple’s leap from computers to a broader ecosystem of devices and services or even Nintendo switching from playing cards to - eventually - videogames and consoles).\nEven avoidance has a place in strategy. But it should be a deliberate choice, not a knee-jerk reaction. Avoidance might mean walking away from an acquisition you FOMO’d in or intentionally exiting a market that no longer offers meaningful returns.\nStrategy isn’t about scrubbing risk out of existence - that’s just hitting pause on reality and hoping nobody notices1. And if Wilde’s theory is correct, we can trust that equilibrium will find us once again.\nThe talk I mentioned at the beginning: There’s an interesting conversation to be had about the Nash equilibrium, but that’s for another time - for now, check out this eloquently written paper.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"3 January 2025","externalUrl":null,"permalink":"/posts/on-risk-homeostasis/","section":"Posts","summary":"Jump into my latest rabbit hole: risk homeostasis theory, or, why we can rethink risk in strategy (and software development).","title":"On Risk Homeostasis","type":"posts"},{"content":"\rThe Concept #\rI was rooting around my ideas backlog and, by pure coincidence, I happened to be working (in my day job) at a horizon scan and technology readiness audit piece. In both my catalogue and work one technology stood out: Auracast.\nIt\u0026rsquo;s kinda fringe for now, mainly used in hearing aids and experimental concert venues. It\u0026rsquo;s an extension of the Bluetooth stack and, unlike \u0026ldquo;traditional\u0026rdquo; Bluetooth, it allows for streaming audio from one source to multiple sinks without having to worry about synchronisation. Pretty cool.\nAlso, I might be a bit of an audiophile (the nerdy kind, not the oxygen-free cables kind). I listen to music for the vast majority of my waking time, but after a while I tend to change my headphones - going from in-ears to over-ears, so that I mix things up a bit (and because after a while my ears need a break from the warmth).\nI also work from home a bunch, which means that, technically, I could have a loudspeaker on. I do have a listening setup in the common room, but it\u0026rsquo;s not exactly portable. To seal the deal, I recently purchased an IKEA outdoor light/speaker - the Vappeby - and I was honestly blown out by how good it sounds for its size and arrangement (single, bottom-firing driver).\nSo, obvious segue, I should design something similar that I could pepper throughout my house, so I don\u0026rsquo;t have to lug speakers around. I\u0026rsquo;d also like the speaker to look nice and demure in the house. Or maybe a statement piece, I\u0026rsquo;m not sure yet.\nAnyways, that\u0026rsquo;s the background. My design constraints are:\nSimple construction Mono audio, stereo/surround when multiple devices are paired together Battery operated Decent (8-hour-ish) playback time Proof-of-concept #\rThis is what I\u0026rsquo;m working on at the minute. I\u0026rsquo;m using the FSC-BT1038B module from Feasycom, mainly because I don\u0026rsquo;t want to sink in the ECAD-time to whip up a IC bringup board. With just a few hours of work I have a sensible design to test. You can follow along in this GitHub repo: fsanzeni/FSC-BT1038B-Barebones-Breakout\rA breakout board designed using KiCad. AIM: test out Auracast protocols to (eventually) build a Bluetooth speaker.\rHTML 0\r0\rA few considerations:\nI\u0026rsquo;ve used a bunch of odd components (namely, the USB port and tactile switches) mainly because I have them lying around. I got them from LCSC. The FSC-BT1038B datasheet asks for a specific LDO which I didn\u0026rsquo;t have in stock. It\u0026rsquo;s supposed to be very low noise at 300mA. I\u0026rsquo;ve substituted fros an AMS1117-3.3v as I have plenty of those. I\u0026rsquo;ve broken out all the pins and grouped them in headers to kinda make it easy to attach external modules. This means some pins are duplicated (e.g., the MIC/LINE ones). I still expect folks to give the datasheet a peruse to familiarise yourselves with which ports can be used at the same time. The boards are 4 layers (signal - ground - 3.3v - signal), just because I didn\u0026rsquo;t want to spend too much time figuring out how to route the various power supplies in a sensible way. I\u0026rsquo;m sure the design could be optimised for a 2 layer board. I didn\u0026rsquo;t bother using differential routing for the USB (also, the pins are criss-crossing for some reason). This shouldn\u0026rsquo;t be a problem at all, since the speeds are really limited - but, yes, it\u0026rsquo;s not best practice. ","date":"2 January 2025","externalUrl":null,"permalink":"/projects/auracast-speaker/","section":"Projects","summary":"Trials and tribulations in developing a Bluetooth speaker ecosystem.","title":"Auracast Bluetooth Speaker","type":"projects"},{"content":"","date":"2 January 2025","externalUrl":null,"permalink":"/tags/bluetooth/","section":"Tags","summary":"","title":"Bluetooth","type":"tags"},{"content":"","date":"2 January 2025","externalUrl":null,"permalink":"/categories/post/","section":"Categories","summary":"","title":"Post","type":"categories"},{"content":"","date":"2 January 2025","externalUrl":null,"permalink":"/tags/project/","section":"Tags","summary":"","title":"Project","type":"tags"},{"content":"","date":"2 January 2025","externalUrl":null,"permalink":"/categories/project/","section":"Categories","summary":"","title":"Project","type":"categories"},{"content":"","date":"2 January 2025","externalUrl":null,"permalink":"/projects/","section":"Projects","summary":"","title":"Projects","type":"projects"},{"content":"I’m going to start this latest ramble by paraphrasing a beautiful paper by Laura Valderrama-Ferrando. She talks about diggers and kings, but I much prefer pirates that can use a rubber chicken with a pulley in the middle. Here it goes:\nImagine a crew of 15 pirates planning to raid two islands: Mêlée Island, with diamonds aplenty, and Scabb Island, stocked with gold. They could either operate as a pirate democracy, sharing decisions and loot, or sail under the rule of a tyrannical Pirate King who owns the ship and makes all the calls.\nLeChuck is the Pirate king in this scenario. Please stick with me.\rOn Mêlée Island, only 7 pirates are fit to dig (the grog at the Scumm Bar is a temptation that few resist), and their efforts would be divided amongst productive and unproductive pirates following some proportion. But on Scabb Island, 8 pirates can gather gold, albeit less valuable than diamonds. In either case, who gets the booty? How is the treasure split? And most importantly, who decides?\nIn the pirate democracy, things are not exactly straightforward. On Mêlée Island, the non-diggers (the majority) force the diggers to accept a smaller cut, leaving most pirates with just a few Pieces O’ Eight. But the hardworking crew keeps most of the loot on Scabb Island, where diggers outnumber the rest. Under the Pirate King, it’s simpler: he takes the lion’s share, leaving everyone else with the bare minimum.\nIf the pirates vote on which island to raid, they’ll pick Scabb Island - more pirates profit. But the Pirate King? He favours Mêlée Island; diamonds make him richer (you can see the exact calculations on productivity on p.3 of Valderrama-Ferrando’s paper). Oddly, the democratic pirates end up stuck in a less efficient setup because they won’t trade their freedom for better loot under the King’s rule.\nAnd we made it to the point of this post: institutional inertia. The word means nothing more than organisations tend to be stuck in their ways, even though a wholly rational reorganisation would lead to better outcomes.\nNow, I hear you screaming from the back of the room, and no, I am not arguing for changing our political system to have kings (although I do live in the UK, which has, I heard, a quite famous Royal Family). I am echoing Jeff Roberts in saying that, despite current significant (geo)political instability, most organisations will not be as affected as you’d think - barring, obviously, major regulatory overhauls (i.e., changing the rules of the game and enforcing them) or military confrontations on a scale we haven’t had in half a century.\nTo be clear, I’m not projecting value judgements on ‘slow’ companies: this behaviour is part and parcel of the Dunbar Number (i.e., we can only keep track of up to 150 people before our brains can’t cope)1. In a mid-sized organisation and bigger, most of the time will be spent making sure everybody knows what they’re doing, oiling the internal processes and tweaking the ever-changing Word templates with updated fonts and logos.\nThese activities will continue, no matter the prevailing political flavour of the moment, due to competitive necessity, contracts in place and established ‘ways of working’. I do believe in and work towards change. Still, I won’t pontificate on silver bullets, AI agents that will make your workforce automated (and obsolescent) or any other doohickey to turbocharge your decision-making. Change is a practice, and, like anybody who has ever tried picking up an instrument, practice never finishes; it just gets slightly less painful with time. But the reward is deeply meaningful.\nYes yes, Dunbar’s number has been ‘debunked’, as the statistical confidence intervals range between 2 and 520 people. This means two things to me: (i) Hurray, we’re all different, and you, the reader, can probably keep track of more people than me, and (ii) my point stays, but the number might not be 150, but 300ish.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"11 December 2024","externalUrl":null,"permalink":"/posts/on-institutional-inertia/","section":"Posts","summary":"How the pirates of Monkey Island can teach us about organisational inertia, or, why companies do not like change so much.","title":"On Institutional Inertia","type":"posts"},{"content":"","date":"3 December 2024","externalUrl":null,"permalink":"/tags/design-futures/","section":"Tags","summary":"","title":"Design Futures","type":"tags"},{"content":"I\u0026rsquo;m deeply fascinated by counterculture(s) and their ability to rally like-minded people around a shared set of ideals. Growing up, I used to hang around with a bunch of misfits: a few punks, lots of nerds (the Warhammer kind, not the computer kind) a sprinkle of sound systems folk and, last but not least, skaters.\nI never fully identified with any of these groups - but that\u0026rsquo;s another story.\nMy point is, counterculture is fascinating and, I argue, we don\u0026rsquo;t have enough of it. Yes, yes, the rise of fandoms is a thing, but my millennial self can\u0026rsquo;t stop itself from wandering what role a physical place should be playing in these increasingly digital culture spaces. To be clear, nothing wrong with connecting with people digitally - I\u0026rsquo;ve met and bonded with many over Discord, over at the Near Future Laboratory or La Locanda Dei GDR (my Italian D\u0026amp;D community that helped keeping me sane during the various lock downs - shout out to Froggy for organising many entertaining quests!).\nAnyways, I find this tension between (counter)culture and place intriguing. And something I kept coming back to while reading the Cult of The Dead Cow: How the Original Hacking Supergroup Might Just Save the World by Joseph Menn.\nThe cDc was (is?) the most famous hacking supergroup, until arguably Anonymous and LulzSec came by a decade or so ago. The cDc had their start with BBS (bulletin board systems, little more than a glorified bacheca where, if you knew where to look, you\u0026rsquo;d be able to download files from).\nVarious members came and went, on either side of the law. They were the first to push - nay, force - Big Tech to take security seriously, they helped establish the protocol for bug hunting and disclosing and were directly involved in establishing the Electronic Freedom Foundation.\nBut all of this came later. In the beginning, a bunch of teenagers with (mostly) angsty handles were writing t-files (shorthand for text files) and exploring phreaking - the precursor to hacking that involved, amongst other things, playing 2.6kHz whistles into telephone receivers to unlock long-distance calls.\nJohn Draper, aka Cap\u0026rsquo;n Crunch, phreaking away in 1978.\rAs Menn often says in his book, the cDc was first and foremost a metaphysical place for publishing articles and generally non-conformist thinking. Their distance from the more, let\u0026rsquo;s say, grey side of the hacker scene left them generally untouched from the various waves of prosecution.\nBut all of that can be found in greater detail in the book, I won\u0026rsquo;t spoil too much. What did catch my eye, though, was a brief anectode in the first third of the book. The author mentioned how Bruce Sterling was clocked on the nose at one of the early hacker meetings.\nNow, this might not mean much to you, but my synapses quite enjoyed that little sentence. Not because Sterling got punched, but because it kinda made it click in my mind.\nFor who does not know, Sterling is an author (mainly sci-fi, with a couple of nonfiction books sprinkled in there) who is best known to me - besides than for his book The Difference Engine, co-authored with William Gibson - for being a pioneer, at least linguistically, of Design Fiction.\nHe wrote, back in the day in Wired:\nDesign Fiction is the deliberate use of diegetic prototypes to suspend disbelief about change.\nBrief sidenote: diegetic prototypes (Kirby, 2010 \u0026amp; 2011) are objects that exist to encapsulate the ethos of a possible or alternative world. Think of Star Trek\u0026rsquo;s Tricorder or wands in Harry Potter. They deceptively seem like mundane objects - because they are. They exist in these alternative worlds, but, when isolated and brought back to our world and context, they are imbued with layers of meaning and symbolism that bring to life the alternative world (or future) they came from.\nDiegetic prototypes, largely thanks to the work of Julian Bleecker and then Dunne \u0026amp; Raby (and many others) are central to design\u0026rsquo;s role in Futures work. They are, to paraphrase Julian, archaeological artifacts from the future. We can design the values, concerns and nuances of possible futures into these objects, and \u0026ldquo;bring them back\u0026rdquo; to examine them, debate and discuss whether the future they come from suits our values.\nOne of my all-time favourite diegetic prototype, by Dr Agi Haines. In her series Circumventive Organs, she envisions a future where bioprinting allows for creating better\u0026amp;improved organs, such as this auto-defibrillating heart.\rI love the idea. But, at the same time, I\u0026rsquo;ve always been relatively reticent to design diegetic prototypes. In fact, my PhD\u0026rsquo;s starting point is a lukewarm critique of the whole idea.\nYes, we should design objects and experiences showing how possible futures might look. Yes, we should have nuanced conversations about these futures - with the broadest set of folks as possible.\nBut I also believe that diegetic prototypes, given that they come from a long tradition in filmmaking, they tend to target only the sense of sight. I can totally recall the shape of a tricorder. But I don\u0026rsquo;t exactly know how it feels. Is it heavy, or made out of some space-grade polymer? Does it faintly smell of hand sanitiser? Are those buttons squishy or tactile switches á la mechanical keyboard?\nAlso, we all know that tricorders are works of fiction. They suspend the disbilief for a brief while, but with a flick of the actor\u0026rsquo;s wrist they\u0026rsquo;re back in the pocket. This is all good when in the context of a tv series or a movie. But more often than not Design Futures operates in workshops and boardrooms. We, as practitioners, cannot run away from the question: How does it work?\nFor some time, I was happy to simply reply \u0026ldquo;it doesn\u0026rsquo;t work, it\u0026rsquo;s a provocation\u0026rdquo;. But the nagging feeling kept coming back. Over time, I realised that a lot can be done with relatively simple means, so there is really no excuse for a diegetic prototype not to be a functioning piece. And here I close the circle with the cDc: we - as in, Design Futures practitioners - should learn more from hackers. Less lip service, more tinkering.\n","date":"3 December 2024","externalUrl":null,"permalink":"/posts/from-the-cdc-to-design-futures/","section":"Posts","summary":"Personal reflection on how hacking culture and Futures work are connected via a punch thrown back in the day.","title":"From the cDc to Design Futures","type":"posts"},{"content":"\rIntroduction #\rThis project has been a long time in the making. To be honest, I haven\u0026rsquo;t dedicated to it nearly enough time - things have been quite hectic in the last year or so.\nAnyway, I\u0026rsquo;m here to formalise the development and show what works, so far.\nThis project is in collaboration with the Near Future Laboratory - special thanks go to Julian Bleecker, Camille MacRae, Cristina Lopes, Dre Labre and Tiffany Hon for their input.\nThe Project #\rThe project is relatively simple: what is the future of timekeeping?\nWe got inspiration from the F91 Kepler watch, a modern re-interpretation of the venerable Casio F91W. Yes, that Casio watch, famous for its iconic, minimalist design and legendary durability. The Casio F91W, launched in 1989, has achieved cult status for its reliability, affordability, and distinctive style - so distinctive that you might get flagged at the airport for \u0026ldquo;screening\u0026rdquo; if you\u0026rsquo;re wearing it.\nWhat Makes the F91W Special #\rThe F91W is not only beloved for its utilitarian design but also its symbolic weight. It’s seen as a democratised piece of tech, accessible to nearly anyone while embodying a time-honored, straightforward approach to design. It features simple alarm and stopwatch functions, a 24-hour clock, and, perhaps surprisingly, an impressive battery life of up to seven years. Have I mentioned it\u0026rsquo;s waterproof too? As a cherry on top, it\u0026rsquo;s priced fairly consistently at 10 local currencies across the world.\nIt\u0026rsquo;s cheap, gorgeous, compact and a design icon. How can we update it?\nEnter the Kepler Project #\rThe F91 Kepler reimagines this classic timepiece for the era of smart-everything. Led by designer Pegor Karoglanian, the project maintains the spirit of the original F91W while integrating modern features and functionality. Kepler enhances the classic watch by incorporating contemporary technology, such as customisable firmware, Bluetooth connectivity, and the option of adding modern sensors via a small daughterboard. It also uses a gourgeous display. I mean, look at that thing.\nPegor\u0026rsquo;s modded F91W. I absolutely love that display.\rOur Interpretation #\rThe Kepler looks amazing. We definitely want to keep an updated screen, preferrably OLED and ideally RGB. We do not want to have, though, sensors and Bluetooth connectivity. It should keep its essence - a dumb, functional, beautiful watch. With the updated screen, though, we can play around with new UIs and ways of showing how time passes.\nShould we show time as a countdown? Should it be relative and unique to each wearer? Are numbers the best way to show time? What about shapes and colours?\nSo many questions, but before we get there, we need a proof of concept.\nCue my preferred ECAD software - Kicad.\nOverview #\rFrom a high level overview, there are not so many components to a watch:\nscreen hardware\rWe need a modern screen. This is not exactly trivial, as modern screens (i.e., OLEDs or similar) draw several orders of magnitude more power than old-school, power-sippin' displays. A problem for another time.\rinput hardware\rSome way to receive wearer input to e.g., set up the time or snooze an alarm. The OG F91W has three buttons, we're aiming to keep the same configuration. We still need a low-power microcontroller to read the interrupts and drive the screen.\rpower hardware\rWe need to power the watch. A standard lithium-polymer battery operates between 4.2v and 3.5-ish v, while we need (probably) a 3.3v source for the microcontroller and the screen. We could use a LDO, but it'd be inefficient. operating system software\rHow the watch ticks (pun intended). Ideally it would be in an accessible format, i.e., in a standard .ino format, so that anybody with the watch could reprogram it on the fly.\rToday\u0026rsquo;s post focuses on the power section.\nUnlimited Power #\rThe F91W uses disposable coin-cell batteries, like this one: These bad bois can power a F91W for up to seven years.\rThe CR2032 (and other similar coin cell batteries) have a very limited capacity, but are very stable and have low self-discharge. That\u0026rsquo;s all well and good, but common coin cell batteries are rated at ~200 mAh (e.g., this Energizer datasheet). Not good enough.\nWe could use rechargeable coin cells, such as the LIR2032. Only problem: these are only rated at ~40 mAh (source).\nOk then, whack in a LiPo battery with associated charging circuitry, a nice little USB connector and you\u0026rsquo;re good to go. Well, not really either. I am a fan of Casio\u0026rsquo;s design and don\u0026rsquo;t what to interrupt it with a USB socket. the watch wound loose it watertight-ness too, which is not ideal. So what to do?\nWireless Charging #\rWould be the ideal solution. Downside: I\u0026rsquo;ve never designed a wireless charger. Reference design to the rescue! Cue in the bq5105xB High-Efficiency Qi v1.2-Compliant Wireless Power Receiver and Battery Charger.\nThat\u0026rsquo;s a mouthful, but it\u0026rsquo;s not terribly complicated. It\u0026rsquo;s an integrated circuit (IC) that uses a standard wireless protocol - Qi - to charge a battery. As a bonus, it comes in a (relatively) easy to hand solder package, if you have a hot air rework station at hand. Together with the TPS63051 buck-boost converter, we should have a stable, low-quiescent (43µA), 1A / 3.3v power rail for the watch. Typical application schematic for the BQ5105xB charger IC.\rTypical application schematic for the TPS63050 buck-boost IC.\rThe schematic I\u0026rsquo;ve come up with is a bog-standard replication of the suggested schematics. I\u0026rsquo;ve added a simple resistor divider and decoupling capacitor for voltage sensing (i.e., to figure out when to charge the watch). It\u0026rsquo;s not the most efficient way to do so, as there are dedicated fuel gauge ICs for this very application, but at this stage it makes sense to keep the BOM small and to have less points of failure in the prototype.\nThe layout, again, simply follows the guidelines in the relevant datasheet. It\u0026rsquo;s a four-layer design, manufactured by JLCPCB (I\u0026rsquo;m not affiliated with them in any way, but I\u0026rsquo;ve used them many times before and their quality/price is fantastic). Please ignore the rest of the board, it\u0026rsquo;s all very much a work in progress (i.e., I screwed up the OLED reset line).\rThe stackup is: signal - ground - 3.3v - signal.\rI\u0026rsquo;ve soldered up a couple boards and it all works fine. I\u0026rsquo;ll spin up a GitHub repo when I have the time.\n","date":"28 October 2024","externalUrl":null,"permalink":"/posts/f91w-log-1/","section":"Posts","summary":"Working on the power circuitry of a re-designed Casio F91W, now with wireless charging.","title":"F91W Log 1","type":"posts"},{"content":"","date":"28 October 2024","externalUrl":null,"permalink":"/tags/open-source/","section":"Tags","summary":"","title":"Open-Source","type":"tags"},{"content":"Companies selling prosthetics with embedded AI systems already exist (Blatchford - UK , Össur - Iceland). What if the algorithm would prevent the user from performing certain actions which are deemed unlayful or \u0026ldquo;unethical\u0026rdquo;?\nThis is a project which shows the dychotomic nature of persuasive technology.\nArtificial Agency is a future company which manufactures prosthetics and augmented limbs, with embedded artificial intelligence which might prevent the user from performing \u0026ldquo;unethical\u0026rdquo; actions.\nIs overriding a person\u0026rsquo;s free will ever ethically acceptable? In this context, who decides what is ethical/unethical? If there isn’t an essential, contextually aware ethical algorithm, how can these problems be resolved?\nHigh-level flowchart for the decisions happening under the hood\rTo understand how heteronomous control feels like, I built a wearable device which through electromyography understands when the wearer is about to swing a punch and prevents the action by activating a TENS (transcuteneous electrical nerve stimulation) machine which cases the bicep and tricep to contract, effectively deviating the blow.\n","date":"14 January 2024","externalUrl":null,"permalink":"/projects/artificialagency/","section":"Projects","summary":"What if the algorithm would prevent the user from performing certain actions which are deemed unlayful or unethical?","title":"Artificial Agency","type":"projects"},{"content":"","date":"14 January 2024","externalUrl":null,"permalink":"/tags/ethics/","section":"Tags","summary":"","title":"Ethics","type":"tags"},{"content":"","date":"14 January 2024","externalUrl":null,"permalink":"/tags/transhumanism/","section":"Tags","summary":"","title":"Transhumanism","type":"tags"},{"content":"","date":"14 January 2024","externalUrl":null,"permalink":"/tags/wearable/","section":"Tags","summary":"","title":"Wearable","type":"tags"},{"content":"","date":"1 January 2017","externalUrl":null,"permalink":"/tags/antidisciplinarity/","section":"Tags","summary":"","title":"Antidisciplinarity","type":"tags"},{"content":"","date":"1 January 2017","externalUrl":null,"permalink":"/tags/bioacoustics/","section":"Tags","summary":"","title":"Bioacoustics","type":"tags"},{"content":"\rEavesdropping on Nature: DIY Bioacoustics is a project focussed on the fruitful entanglement of design, science, sound and the public sphere. Our goals are to advance both design and science by “thinking about the future of science in the context of design–as well as design in the context of science” and to prototype the process in a way which is in accordance with open source and DIY methodologies.\nIn collaboration with Alice Potts, Minwoo Kim, Davin Browner-Conaty, Cambridge University and the John Innes Centre Department of Crops Genetics.\nThe project is completely open source. You can find the updated harware schematics and datasets on Github. Biomaker/16_DIY-Bioacoustics\rnull 3\r1\rScientific Basis #\rWe will be developing an open source and DIY sensor/service for biologists, using sound recordings to identify and track different species of leafhoppers, to monitor crop health remotely. The sensor/service could also be utilised by citizen scientists, farmers and visual artists/computational designers.\nNon-invasive bioacoustic monitoring has become an increasingly effective way of monitoring ecosystem diversity and health. Bioacoustics paired with machine learning has been cited as an effective way of automatically identifying animals such as frogs (Xie, 2017), birds (Zhao et al, 2017) and fish (Sattar et al, 2016) amongst other animals. Bioacoustics is an area of scientific research which would benefit from (i) continued expansion of machine learning and automated identification of insect species (ii) creation of open source hardware for conducting research. Our aim is to contribute to (i) by applying bioacoustics and machine learning to insect recognition and to (ii) by creating an open source, diy and hackable acoustic sensor for identification of various insect species.\nRecent work on insect recognition and intelligent traps is seen in (Silva et al, 2014) and on methods of creating low cost sensors for insect recognition in (Silva et al, 2015). Problems with ambient noise in traditional acoustic recording are identified in (Chen et al, 2014) and they show how low cost optical sensors provide more accuracy and high data capacity than previous methods. We hope to build on this work by creating an innovative open source model and associated hardware for conducting research into insect ecosystems.\nInsects are vectors of diseases while also pollinating a large proportion of the world’s food production. Further to this, they also constitute a growing food market which is expected to be worth 55 billion dollars by 2023. (Global Market Insight, 2016).\nOur aim is to contribute to ongoing research into insect recognition and ecosystems by applying bioacoustics and machine learning to insect recognition and to the democratisation of scientific research by creating an open source, diy and hackable acoustic sensor for identification of various insect species. The final sensor would be non-invasive, weatherproof and wireless and would link to a dashboard, displaying visually the patterns and statistics gathered which could eventually be linked to and open data structure such as wiki data for sharing information about various environments throughout the world. In the first phase of development we will be using already available kits on the market for rapid prototyping and proof of concept. The second step will be creating a custom PCB which would fit all of the necessary components and circuitry. On the software side, we will be relying on open source projects, such as SuperCollider. We hope that our research will contribute to the development of the use of bioacoustics in the study of insect ecosystems while also furthering the democratisation of science.\nFurther Background #\rHuman interpretations of insects are subject to what (Whaley, 2006) calls the deception of dissimulation (the hiding of the real). They are interpreted as swarm-like templates for technologies or as having a kind of language for example. This is the product of a constant human impulse to interpret animal behaviour on terms which are already intelligible to us. We cannot move outside of this intelligibility and as a result, have a tendency to create approximations of identity through myth or compromise. These compromises are a kind of useful fake.\nWe are interested in a particular myth that persisted for many years about the Homoptera, Cicadellidae or “Leafhopper” which was dispelled by the research of Frej Ossiannilsson in the 1940s (Ossiannilsson, 1946 and 1949). Leafhoppers were consistently classified as being “Muettes” meaning the “dumb ones” or “Silentia” meaning “silent, stillness, quiet, noiseless”. In contrast, their larger cousins the Cicada were “Chanteuses” meaning “Singers” or “Stridulantia”. Leafhoppers were, then, the supposedly silent yet ubiquitous scion of the more commendable aesthetic qualities of the Cicada. However, they can be found on all continents, in nearly every habitat that supports vascular plant life and have an intimate relationship with those plants choosing to feed on their above-ground stems or leaves. Their feeding distorts and reshapes plants through puncturing and suction of plant juices and leaves traces through curling, stunting, white blotches, drying, yellowing and distortion depending on the specific activity and sub species. Their proscribed silence was ended when Ossiannilsson laid the groundwork for studies of how the Leafhoppers interaction with plants in another way: through vibration and sound.\nImms (1951) states that sound making was unique to the cicadas and that other members of “Auchenorrhyncha” did not produce sounds. What Ossiannilsson shows is a kind of failure of listening on the part of the previous studies. Instead, as shown in recent studies building on Ossiannilsson, Leafhoppers transmit signals through plant material substrates. These signals are still faint to the human ear so special amplifying equipment is needed to tune into this mediated acoustic behaviour. Leafhoppers do this because their small size means that to communicate through open air would require “singing” at an extremely high frequency and these high frequency transmissions are not suitable in their plant rich environments due to scatter, reflection and interference. To avoid this they communicate vital information, between sexes, through the plants. What is apparent in the communicative behaviour of the leafhopper and its plants is a kind of “ecological exformation” from the perspective of human perception. This is to say that the acoustic interaction between the plant and the leafhopper is an unknown in the tuneable reality of the human ear. It is a communicative interaction which is crucial for the planet (for example: revealing crop health) yet it is only realised following Ossiannilsson’s research and through technological innovations such as amplifying equipment. New acoustic information is discovered or revealed as a result of treating the Cidacellidae’s communication channels as radically non human; as vital information transmitted through the vibration of plants. This exchange creates a micro interaction where a kind of bio-semantic meaning can be decoded through different technological tunings into reality. For example, through bio-acoustic information and sound. This information forms a point of communicative anastomosis between human, machine, plant and animal where bio-exformation turns into bio-information which can be decoded and utilised by the person, farmer, citizen, observer or scientist. It becomes vital information, shared between everything that attends to it.\nOur question is, then, how can this acoustic and neuromuscular information be organised and attended to by biologists, farmers, artists, designers or citizen scientists? How can sonic technology and machine learning aid this process? Our aim is to build the potential for a media ecological system surrounding the leafhopper through open source bioacoustics and machine learning. The outcome will be a DIY sensor/service for biologists, using sound recordings to identify and track different species of leafhoppers in order facilitate the translation and exchange of vital information. We hope that aspects of this media system can be used by farmers to monitor plant or animal health remotely, in visual art or computational design projects or by citizen scientists.\nMethodologies for Linking Design and Science #\rThe project is being approached through an antidisciplinary design framework. The production of the sensor will rely on entangling bioacoustics, citizen science, open source and diy technological development and public science. Interdisciplinarity is vital to achieving breakthrough work across disciplines. Interdisciplinary work is when a group of people from different disciplines work together, while anti-disciplinary work is a process which temporarily or permanently suspends existing knowledge structures in order to facilitate the creation of something innovative and new. Anti-Disciplinarity is “about working in spaces that simply do not fit into any existing academic discipline” (Ito, 2016).\nBioacoustics #\rBioacoustics, or acoustic ecology, is the mapping of biological ecosystems through sound. It presents the opportunity to listen to but also eavesdrop on nature and one of its central ideas is:\nDiversity in the soundscape = diversity in the landscape.\nOur collaborators at the John Innes Centre for Plant and Microbial Sciences are studying how leafhoppers communicate information between one another, by vibrating plants. More specifically, they are interested in how leafhoppers change their acoustic behaviour when residing on plants adversely affected by the bacteria Phytoplasma? In other words, how it might be possible for leafhoppers to communicate the health of plant ecosystems to humans. What is apparent in the communicative behaviour of the leafhopper and the plant substrates it communicates through is a kind of “ecological exformation” from the perspective of human perception. This is to say that the acoustic interaction between the plant and the leafhopper is an unknown in the tuneable reality of the human ear. Using technology, we can eavesdrop on this communication in order to uncover vital information about the health of ecosystems, which might be utilised by the farmer, citizen, observer, scientist or custodians of local parks and wildlife. It becomes vital information, shared between anything that attends to it.\nOur aim is to build the potential for a DIY sensor for biologists which will use sound to identify and track different species of leafhoppers in order to facilitate the translation and exchange of vital information. We hope that aspects of this media system can ultimately be used by farmers to monitor plant or animal health remotely, in visual art or computational design projects or by citizen scientists.\nCitizen Science and DIY #\rEqually important to our project is the notion of citizen science (the practice of the scientific method by non-professional scientists) and DIY. Both are focussed on how science can become actionable within the public sphere and how the methods of, for example, biology, might be extended beyond the institutional research lab by making legitimate the claim that:\nScience = A routine activity that is open to anyone.\nA central part of our vision of citizen science and DIY is the idea that scientific technologies should be made publicly available and actionable. We think that this is done by developing biological technologies in a way so that they are approachable, co-designed and linked to a continuing process of knowledge sharing and exchange. The DIY movement, through its principle that the basis of decision making is always better when it\u0026rsquo;s made by the people who are directly impacted by that decision making, provides an interesting practical framework for citizen science. In this sense, both the DIY movement and citizen science, are radically anti-disciplinary; consistently asking questions like: What constitutes knowledge? Who’s authorised to validate knowledge? As well as: how to make, build things and conduct experiments?\nOur aim is to fuse these great traditions and make scientific technology actionable for as diverse a set of people as is possible. The goal is to open the “black box” of research by promoting scientific literacy, relocating the site of research away from institutions and opening up the scientific method to the multiple cultures of exchange that exist in society.\nScience In Public #\rBy the measure that imitation is the most sincere form of flattery it\u0026rsquo;s clear that humans have an, often undervalued, love for the sonic qualities of insects. Our aural and emotional response to insects is evident in the onomatopoeia of the word “buzz” to the influence of the cricket in compositions like Béla Bartók’s solo piano piece: “The Night’s Music”. Bartók was an amateur entomologist, owning a large collection of beetles and flies, and his marrying of scientific curiosity and entertainment is something that we want to replicate.\nA combination of hard science, serious play, sound and the empowering force of DIY and citizen science means that both design and science can be understood and absorbed by people external to the design process. We think that through sonifying and DIY-ing the study of insect behaviour as a form of entertainment, provided by nature and contextualised by culture, we can create an experience that can be re-utilised and expanded. In effect, we will achieve our goal of increasing engagement with ecological systems by opening the door to everyday sonic experience of ecological sound.\nThe aim then, returning to the leafhopper, is to enable people to whistle a tune that has never been whistled before; to understand, in a qualitative sense, the acoustic structure and polyphony of ecological systems that surround us.\nBibliography #\rWhaley, S. “Detecting Deception: A Bibliography of Counterdeception Across Time, \u0026ldquo;Cultures, and Discipline”. (2006).\nChen, Yanping, et al. \u0026ldquo;Flying insect classification with inexpensive sensors.\u0026rdquo; Journal of insect behavior 27.5 (2014): 657-677.\nBardeli, Rolf, et al. \u0026ldquo;Detecting bird sounds in a complex acoustic environment and application to bioacoustic monitoring.\u0026rdquo; Pattern Recognition Letters 31.12 (2010): 1524-1534.\nIto, Joichi. (2016). Can design advance science, and can science advance design? url: https://www.pubpub.org/pub/designandscience\nOssiannilsson, F. On sound-production and the sound-producing organ in Swedish Auchenorrhyncha (A preliminary note). Opusc. Entomol. (1946). 11:82-84.\nOssiannilsson, F. Insect drummers. A study on the morphology and function of the sound-producing organ of Swedish Homoptera Auchenorrhyncha with notes on their sound-production. Opusc. (1949): Entomol. 11:82-84.\nSattar, F, et al. \u0026ldquo;Identification of fish vocalizations from ocean acoustic data.\u0026rdquo; Applied Acoustics 110 (2016): 248-255.\nSilva, Diego F., et al. \u0026ldquo;Exploring low cost laser sensors to identify flying insect species.\u0026rdquo; Journal of Intelligent \u0026amp; Robotic Systems 80 (2015): 313.\nSilva, Diego F., et al. \u0026ldquo;Applying machine learning and audio analysis techniques to insect recognition in intelligent traps.\u0026rdquo; Machine Learning and Applications (ICMLA), 2013 12th International Conference on. Vol. 1. IEEE, 2013.\nZhao, Zhao, et al. \u0026ldquo;Automated bird acoustic event detection and robust species classification.\u0026rdquo; Ecological Informatics 39 (2017): 99-108.\nXie, Jie. \u0026ldquo;Multi-label classification of frog species via deep learning.\u0026rdquo; PeerJ Preprints 5 (2017): e3007v1.\nGlobal Market Insight \u0026ldquo;edible Insects Market Size, Share - Global Industry Report 2023.\u0026rdquo; [online] Available at: https://www.gminsights.com/industry-analysis/edible-insects-market.\n","date":"1 January 2017","externalUrl":null,"permalink":"/projects/diybioacoustics/","section":"Projects","summary":"Open source sensor/service for preemptive detection of pests in crops.","title":"DIY Bioacoustics","type":"projects"},{"content":"","date":"1 January 2017","externalUrl":null,"permalink":"/tags/essentialism/","section":"Tags","summary":"","title":"Essentialism","type":"tags"},{"content":"It\u0026rsquo;s all about connecting disparate groups: people with very different lives and low alignment in terms of worldview, skills or expertise can spark off each other and increase the feeling of inventiveness and surprisingness within a group.\nThis project started as a research piece on possible methodologies on approaching the unknown unknowns, namely, future wicked problems. An initial methodology was developed, inspired by complex adaptive systems, future forecasting and non-essentialism, especially the open textured concept.\nProject overview in poster format\rIntroduction #\rThe ideas we would like to explore in this paper centre around wondering what can be done to enrich the work of transdisciplinary groups and designers when they try to engage with how the future ought to be or how to proceed in order to work with the future in mind. We would also like to speculate on how we could humanise social randomness and complexity so it matches up with human needs and desires.\nHaving outlined this we will then argue that transdisciplinary or non disciplinary teamwork is an essential component in dealing with the often elusive problems that complex adaptive systems throw up. The second half of our paper will then deal with some strategies which we think might be useful for interdisciplinary teams dealing with complex and elusive problems. This will act as both a survey of existing options as well as an attempt to come up with some new processes, methods or creative prompts which might be useful.\nAs interdisciplinary practitioners we are interested in looking at how design (specifically speculative, systems and post industrial design practices service systems and product service systems) can interact with disparate actors from other fields of study. Our purpose here is not to prohibit team members using insights developed in their respective disciplines. Specialised study and research is important. Instead, we want to try and open up a space for transdisciplinarity for when people with disparate backgrounds need to work together on complex and elusive problems which may emerge now or in the future.\nComplex Adaptive Systems #\rComplex adaptive systems are bodies of interdependent, dynamic entities and information which exhibit properties and behaviours that are emergent in nature and not necessarily apparent from analysis of the individual parts. A person’s facial structure, which we all recognise and process instantaneously, is an example of a complex system. The nose, eye(s), mouth, cheeks, chin, etc. contribute to something which is more that the sum of their parts. Similarly, both sides of the face look very different when looked at separately. However, when paired they produce a further emergent object which forms facial structure. Facial structures then influence further patterns of behaviour and emergent social properties.\nA stronger example of this is in nature, for example when you put hydrogen and oxygen together you get water. Water has properties like wetness which are not apparent in hydrogen or oxygen as parts. There is a kind of “surprisingness” to this emergent information. A pattern that is in the whole but not in the parts is surprising in an information theory sense and predicting that pattern is difficult in a computational sense, put these things together within a system and you get things which you are surprised by.\nA complex adaptive system might be a natural, non-human system such as an ant colony or it might be a human system like a human’s immune system or it might be a human made system such as a transport network. Further to this, we might add a fourth category of the artificial system such as an algorithm or artificial intelligence.\nA complex adaptive system is categorised by “complex behaviours” which are emergent from “often non linear spatio temporal interaction among a large number of component systems at different levels of organisation”.\nX points to a useful definition of complexity given by Rosen and Mikulecky where complexity is the “property of a real world system that is manifest in the inability of any one formalism being adequate to capture all its properties” (page, year). In this sense it’s possible to argue that there is a lack of an essential formalised notion that captures the dynamic of all of the possible interactions with a complex adaptive system. As Rosen and Mikulecky argue the “formal systems needed to describe each distinct aspect are not derivable from each other”. In other words it is impossible to find a universal and formal indicator of how these systems will operate and therefore “distinctly different ways of interacting” with different systems are required.\nSo, it is possible, combining our outline of emergence and surprisingness and the above definition of complex adaptive systems, to make the following argument. Complex adaptive systems exhibit: (i) an obfuscation of basic cause and effect models, (ii) the patterns or behaviour of the sub parts of these systems is not necessarily apparent in the emergent properties they produce, (iii) dynamic and multifaceted interactions and (iv) strategies for dealing with problems relating to an inability to predict or preempt these “surprising properties” cannot, therefore, rely on essentialist, formalistic or reductivist based strategies alone.\nComplex Social Systems #\rWe live and practice art and design within one subset of complex adaptive systems: social systems. Social systems exhibit emergent properties that are often surprising and are adaptive in the sense that sub parts react to actions by other sub parts and the system as a whole exhibits interdependence between sub parts. Because of these factor cause and effect often seem random. In other words the emergent properties have a certain “surprisingness” to them and the interactions between sub parts are hard to map or engage with. Individuals also exhibit complexity. This follows the argument that individuals are not simply rational homo economicus or an advertising persona. They exhibit the same complexities as the people you actually know rather than those based on abstracted or simplified models.\nSystems theory is a vast research area and we highlight it here, in order to relate complex adaptive systems to design and transdisciplinary teams. We will now outline what we mean by those two terms.\nBy Design we are referring to any design practice which includes a consideration of human interactions with a system. So, the target area is large. Our background is in service, systems, speculative and communication design as well as philosophy and the social sciences. The aim of this paper is to provide, from that initial perspective, a way for transdisciplinary teams to incorporate some of the methodologies and ideas we have picked up from our area of expertise.\nThe rest of our paper will consist of an exploration of an argument from 20th century philosophy and art which we think is pertinent to the themes we have addressed so far: the open textured concept. Further to this we will speculate in relation to a couple of areas where we think this idea could be developed relating to working in transdisciplinary teams on complex problems.\nThere is no exhaustive list possible for the things that people from diverse backgrounds can do to work better together so we thought we would offer some that we have found useful throughout our research.\nTransdisciplinarity #\rOne response to the problems created by complex adaptive systems is to problem solve by employing transdisciplinary research and practice. This due to the new kinds of knowledge synthesis required to tackle these problems. Specialisation and mono-disciplinary silos are, in some cases, an impediment to progress.\nMono, multi, and interdisciplinary approaches are valuable producers of knowledge and the latter two allow for interesting cross pollination between defined disciplines. However, transdisciplinarity produces a new way of looking at knowledge communities, working with other people and complex problem solving or responding.\nThe first thing we’d like to suggest is that transdisciplinary work relies on transjective reasoning. This is where a group is treated as consisting of an open community of inquires and their shared knowledge of the world should work in a way that reflects their characteristics. This might be in the form of taking a transdisciplinary approach or might be termed anti discipline. Either way the collective notion of truth is a pragmatic “truth” and is something that is only approached over time by the open community of inquirers. There may be no immediate solutions apparent but this is accepted because of the nature of dealing with complexity and the surprising nature of the problems thrown up by this.\nRecommendations for Transdisciplinary Teams:\nTreat the world as consisting of complex adaptive systems There are no totally encompassing solutions. Incorporate informal play and imagination into your practice. Think about what language or concepts you are using. There is much more room for fruitful overlapping between disparate disciplines. Be open to new transdisciplinary or anti disciplinary concepts. Incorporate insights from outside of the culture of your group. Use open source as a metaphor for thinking about transdisciplinarity. Refuse to simplify or beautify complex problems. Another argument we’d like to make is that as an actor within an interdisciplinary team you don’t “just” do anything. In monodisciplinary teams a large number of assumptions are taken to be valid. So for example a group of catholic priests will agree on the general concept definition for “marriage” or a team of engineers might agree on a method of linear analysis of solids and so on. In transdisciplinary teams many similar assumptions, if assumed, will lead to members talking past one another, not being able to progress or even explain themselves easily. This situation seems analogous to speakers of different languages all talking to one another as if each will understand. One response to this might be to invent a metalanguage for interdisciplinary teams or find a quick way of matching or explaining concepts that do not align easily. A metalanguage could be a coded procedural language or could be visual or virtual.\nTransdisciplinary teams should be able to speculate, be able to dream and imagine about the present, future or past, think about the human systems they are engaging with and also problem solve, use data effectively and understand the natural facts or social norms related to the problem area.\nTransdisciplinary teams might be better situated to deal with human systems by including random citizens in their group work or include people who are from a disparate social group to the members of the team. By this we mean selecting someone randomly off the street or organising a platform whereby the collaboration can take place. This person will not be a surveyed subject or individual data set. Instead they act as a member of the interdisciplinary team. We can imagine a reaction to this: that the person will not be informed! If anything this is a moot point because the nature of transdisciplinary teams is that you might have max one person who exhibits expertise in a given area. What is paramount here is giving the citizen or disparate group a voice and also to show that experts should not always be the sole purveyors and dealers in public problems.\nOpen Textured Concept #\rOne argument we’d like to make in reaction to the ideas explored in the first section is that transdisciplinary research and practice can be fruitfully explored using the notion of an open textured concept.\nThe idea of an open textured concept is a relatively new one, arising out of the philosophy of Ludwig Wittgenstein and the art movements of the early 20th century. It runs contrary to an essentialist view of art (and by extension design) which, in terms of the western or european philosophical canon, runs back to Plato.\nPlato argued that entities and our perceptual experience of them are split roughly between the following categories: ideal (idea) , object and picture. Under this argument art is always three steps away from idea and is tied to aesthetic perceptual experience or more importantly - limited to aesthetic experience. This is what we mean by an essentialist view of art. Taking essentialism as a general position we can say that it implies the ability to deduce that something is art or design based on its reducible properties. There is a ready made solution to the question what is art? Namely, that is something which is based in a purely aesthetic appearance: “the painting was beautiful” or “I fell in love with the curvature of the sculpture, it was fantastic!”. This essentialist view carries forward to Clive Bell, an English critic associated with formalism, for example in his 1914 work entitled Art. Within this he argues that when we look at some artistic object compared to some other non artistic object say a cup of coffee or a pen we have a distinct aesthetic experience relating to the artwork and not to the non artwork. This, he implies, means that the artwork can be explained as having a significant form while the cup of coffee or pen are not in possession of this significant form. We can say that Bell’s significant form occurs when an entity is structured, in such a way, so that their arrangement provokes an emotional response in the viewer which is particular to the object. You can’t necessarily show significant form but the key relationship is between the triggering of an emotional response to the particular structure of colour, shape etc.\nGiven the 21st century’s inheritance and normalisation of modernist and post modernist arguments about art and design, we will quickly sketch out some interesting aspects of this change and then explain the idea of the open textured concept. According to Bell, if there’s content outside of the aesthetic experience then it does not count as art. If the object is the coffee cup or the work is overtly political than the work does not count as art under Bell’s terms.\nOne major reaction to this is something like Marcel Duchamp’s anti-aesthetic or anti-retinal art. Which is centred on the question of what is it, apart from aesthetics, that makes something a work of art.\nOne aspect of art is, quite obviously, that they are made by artists, appear in art institutions, have titles not names and it might require that an expert say it’s a work of art and if they do then that means that it probably is a work of art. You might go visit a doctor when you are sick in the same way that Duchamp would suggest that you go see an art expert if you want to check if something is a work of art:\nA: Made by an artist. B: Appears in an art institution. C: Has a title not a name. D: If an expert deems it art it probably is art.\nE: ? (Some further extension of the concept or an argument to challenge the previous assumptions).\nA philosophical analogy can be made here in relation to the later writings of Ludwig Wittgenstein. Wittgenstein counters (over the course of Philosophical Investigations (1953) ) an inherited notion, from the history of philosophy, that we can know the “essential” identities of things through disambiguation between those entities “essential” properties. So, for example we can tell the difference between a camel versus a cow versus a train because each has a central “essential” definition which distinguishes it from another and this has been internalised. Platonic form is an example of this idea where each entity is related to a perfect form “the cow” and so on with deviations within that concept apparent in the individual.\nIn order to challenge this kind of argument, Wittgenstein, makes use of the concept of a language game and convention. He asks the question is there an “essential” quality, that without which a game would cease to be a game? There are games that we play outdoors and indoors, games that include balls and games that don’t and so on. He argues that, therefore, there is no “essential” definition for a game. Instead what games do have is family resemblance. We can list these resemblances and we can make inferences based on these resemblances. So, for example we can look at cousin John and say that he reminds us of aunt Betty or that football reminds us of rugby and so on. (The inexhaustibility of the related qualities of games means that there is no central, “essential” conception of them available). In this case concepts cluster around certain resemblances without there being an “essential” definition or central reducible aspect.\nAn relevant application of Wittgenstein’s game theory is in defining art. Applied to art his theory of games would look like this: were we to search for one thing common to all work works of art we would find that while there isn’t a single characteristic common to them all,they do share likenesses or resemblances. For example were I to put 100 different objects in a room and only one of them was a work of art, another person would probably be able to pick it out because she recognises the necessary conventions that comprise art’s identity, i.e. a frame and paint on canvas.\nMorris Weitz writing in (Weitz, 1956) attempts to deal with the problems relating to the question “what is art?” which became apparent as a result of modernist unconventionality in relation to older more traditional works. A reformulation of the requisite categories of art, in line with Wittgenstein’s arguments above, was centred around the idea that art was a sort of open concept. That is to say that it is non “essential” and without necessary and sufficient conditions which are tied to aesthetic experience alone. A central argument Weitz makes is that we learn the right use of words and concepts relating to entities through observing how others use the word in certain situations. That is to say, that we learn by playing a language game about the supposed objects of art and that our conception of art (and our ability to pick out the art-object in the room of 500 objects) is based on an inference from those linguistic and social conventions.\nWorks of art, then, are part of a certain collation of a particular kind of collection of objects and traditional aesthetic theories of art are based on a false logical premise because it is not possible to isolate the necessary and sufficient conditions that make up a work of art through aesthetic experience alone. In this sense the category of art might be said to be non tautological or in Wittgenstein’s terminology: “nonsense”. That is to say that it is neither related to natural facts which for example the sciences might try and discover. Neither is it related to tautology or logical and mathematical reduction. Instead because of the lack of necessary and sufficient conditions for works of art the category can be said to be an open and inferential concept.\nWeitz’s notion of an open concept is:\nA concept is open if its conditions of application are emendable and corrigible; i.e. if a situation or case can be imagined or secured which would call for some sort of decision on our part to extend the use of the concept to cover this, or to close the concept and invent a new one to deal with the new case and its new property. (Weitz, 1956 , 31)\nA closed concept is one in which:\n[\u0026hellip;] necessary and sufficient conditions for the application of a concept can be stated, the concept is a closed one. But this can happen only in logic or mathematics where concepts are constructed and completely defined. It cannot occur with empirically-descriptive and normative concepts unless we arbitrarily close them by stipulating the ranges of their uses (ibid, 31). By giving an “essential” definition of art you are closing a concept which is an open concept. In other words, art does not have ubiquitously transferable qualities that can be picked up from one set of things and linked, via an “essential” definition of the form “art”, to another set because there are no necessary and sufficient conditions for that definition.\nThere are a number of problems with this argument such as: (i) Wittgenstein’s idea that use is the main criteria for a concept, specifically use related to linguistic use and concepts. (ii) We, roughly speaking, share a conception of art such that, in the very least, we know what we are talking about when we mention a renaissance painter and a post-modern artist in the same breath.\nGiven that (i) is based on Wittgenstein’s full argument outlined in Philosophical Investigations it can be left aside here. The counter argument in (ii) is more easily dealt with because, we can assume, that Weitz’s point relates to non “essential” and therefore ubiquitous definition exists for art. In other words, there is not a closed set of concepts and related necessary and sufficient conditions from which we can draw in order to uncover a real definition for art.\nTaking up this argument, we would like to maintain that open textured concepts are an important asset for not just those thinking about art but also involving design (the link here is pretty obvious), social behaviour, transdisciplinarity and potentially beyond. We’ll refine what we mean by giving an example related to art and then try and repurpose this for the other categories listed. In addition, we want to suggest that there are a cluster of methods, concepts and ideas that are interdependent with the open textured concept and that these form a useful partnership for design and transdisciplinary teams when attempting to deal with complex problems. We think that open textured concepts are a way of thinking about and managing complexity which might be a useful starting point for those trying to plan, react to or design for complex social, environmental or human problems which may not have solutions which are apparent or readily available.\nChris Burden’s piece “747” involved the artist going out onto the runway at LAX and firing bullets at a Boeing 747 taking off. The immediate question here is whether this can count as a piece of art? There’s a preponderance of evidence to suggest that it is but there is no guaranteed that it can count as a work of art. In a later work Burden tasked a man with a sniper rifle to shoot him in the arm. Again the question remains as to whether there is any meaningful or reasonable information that can be used to infer that Burden’s activity can be included in the convention of what counts as art?\nChris Burden\u0026rsquo;s Performance at Los Angeles, January 5, 1973\rSo, lets check:\nA: Is made by an artist? (Y) B: Is displayed in an institution? (N or at least not directly) C: Has a title not a name? (Y) D: Is deemed to be art by an expert? (Y, although this might be changed to “by at least one expert”)\nSo, given the open concept argument we can add another category for both works: E: New quality of art: e.g. shooting at 747 or enlisting your fellow man to carry out attempted murder on yourself.\nE throws up all sorts of definitional problems which can be said to be apart from any “facts” of the case. Further to this, it’s not apparent as to whether there is an exact solution to E. Or at least it’s easy to imagine how a hypothetical argument or negotiation (say between Clive Bell and Burden) over E might proceed but very hard to see how it would be resolved. Therefore, the solution to E is not apparent based on any facts of the matter, any “essential” form we can point to nor based on logical inference from aesthetic experience. If this argument is right, then, it opens up some interesting possibilities for those areas of art and design which try to solve complex problems outside of the traditional borders of those disciplines. Next, we will outline a couple of ways this could proceed in relation to the concept of emergence and “surprisingness” in complex adaptive systems and strategies for dealing with the wicked/complex problems those systems throw up.\nPotential Extensions of the Open Textured Concept #\rAn interesting extension of the idea of an open textured concept is an argument emerging from meta metaphysics and ethics. Philosophers such as (Amie Thomasson, ) and (Plunkett and Sundell, 2013) are exploring how the sorts of debates over definitions, concepts and language rather than facts impact on how we conceptually sort out and disagree over social categories and norms, ethics, categories of scientific classification and also themes relating to Weitz’s initial argument relating to works of art and design.\nFor example, New York City recognises 32 separate gender identity possibilities (ref). Presumably, someone in New York still believes that there are just two possibilities: man and woman. Our interpretation of conceptual ethics, following the idea of the open textured concept, is that it is chiefly concerned with mapping the definitional, conceptual and linguistic debate between these two (or more) potential divergent positions and then using that map to better understand the kinds of “first order” ethical debates people have relating to what is or ought to be the case.\n(Plunkett and Sundell, 2013) argue that these two hypothetical parties: the city of New York and the person who disagrees with their position on gender are engaged in a dispute not over the facts of the case but rather one that is definitional. Using their terminology the parties are involved in a “metalinguistic negotiation” (2013, 3). This is “disagreement (which) is reflected in such a linguistic exchange..(via) a largely tacit negotiation over how best to use the relevant words” and what sort of metalinguistic usage the term should subscribe to in that given context (3). This relates to exchanges where the terms “meta linguistic usage” where “linguistic expression is used (not mentioned) to communicate information about the appropriate usage of that very expression in context” (3). They describe this process as a metalinguistic negotiation which has two elements: (i) a mutual sharpening and negotiation of the metalinguistic usage in question between users and (ii) the normative question of how best to use a concept relative to a particular context. This way of looking at disagreement is pertinent to exchanges where there is an indeterminacy antecedent to the particular dispute which applies to what we have discussed so far in this paper.\nThe point for designers and those working in transdisciplinary teams is to both internally (within the working group) and externally (in the world outside the group) acknowledge this aspect of how we rationalise and think about our assumptions about what should be the case and how this contrasts with others.\nWe want to argue that these sorts of groups ought to keep in mind the following steps when dealing with divergent ideas or assumptions:\nA. (Internally within the group):\n(i) Temporarily disallow for the idea that there must be some fact or truth hiding behind the divergent ideas. The meanings involved are related to convention, usage, x’s language and concepts in divergence to y’s language and concepts.\n(ii) Try and sort out if there is actually divergence by using paraphrase (Chalmers, 2011), if the paraphrase does not lead to a change in the divergence then map out the real and substantial differences so that parties are not merely talking past each other.\n(iii) Try and use another way of representing the information e.g. through colours, drawings or again by paraphrasing the language that you are using to convey your point.\n(iv) Finally, if the divergence is real and substantial then allow it to exist like that and move on. The allowance for this might lead to interesting solutions later on.\nB. (Externally: When Trying to Categorise the Complex Social Systems you are Designing for) (i) Map out the conceptual possibilities for some target groups or topic such as gender or works of art. Temporarily disallow for truth or notions of wrong and right relating to the respective groups.\n(ii) Again, try and sort out the extent and nature of the divergence by paraphrasing the language and concepts in question. This is to ensure there is actually some real divergence rather than superficial or “merely verbal”, in Chalmer’s (2011) terms, disagreement or divergence in question.\n(iii) Try and represent the information through data, visuals (abstracted such as a drawing or painting or using clear visual information). Then reflect on how this might allow for a new paraphrase or insight on the original problem.\n(iv) Again, if the disagreement or divergence is still apparent then it is real and shouldn’t be challenged further.\nA similar idea has been popularised recently in the form of people exhibiting a bias. The problem with using this term and its related ideas is, for us, that it implies that people should necessarily repress and control their bias or propensity to believe x. Conceptual ethics is a much more flexible and open way of addressing some of the problems people associate with biases but without making the process inherently political or introducing a need to repress the things people really feel ought to happen. In our view conceptual ethics gives a framework for discussion and exploration rather than presenting a need to “check your” biases if a majority of people in a group do not share the same assumptions. In other words, it allows for there to be real disagreement where it might actually occur and tries to prevent against individuals talking past each other when real disagreement is not apparent.\nMethods for Trans-Disciplinary Teams Deling With Complex Problems #\rOn the 3rd of December 2016 we conducted a workshop to trial some of our ideas and methods within a transdisciplinary group. Our group consisted of persons from the following backgrounds: philosophy, computer science, art, design, communication design and history. The following were methods that we trialled:\nOblique Processing #\rAnother important element in thinking about and using open textured concepts is being able to stimulate discussions which can lead to potential changes of convention or thought in relation to A-D and also generating new possibilities for E. One method we found useful for this was trying to find ways to generate ideas obliquely or by avoiding linear reasoning. Using Brian Eno and Peter Schmidt’s Oblique Strategies as a template we came up with a set of prompt cards which specifically deal with complex problems, possible worlds and our human perspective on both. We included a number of blank cards, on which participants could write in their own questions. The point of this is to induce oblique processing within teams. This is useful because it allows individuals to offload their rational thinking to prompts or questions which then (hopefully) stimulate invigorating discussions or ideas.\nFind a Random Input #\rIn our case we choose to use children’s responses to questions about the future of exploration and discovery in order to stimulate thinking in an adult research group. There are countless other ways of trying to achieve this effect.\nFor example you might link with players of virtual reality games or you might enlist a random person on the street.\nPossible Worlds #\rWe can split the present into the following variables: time (t), person (p), world (w), context (c).\nWe can then change all of the variables in order to imagine some possible world (pw) where some things may be different and others not. Participants were asked to insert and then change a variable in each of the above constraints in order to come up with an imagined possible world. The point here was to show how the constraints can be used to come up with ideas and imagined outcomes or possible worlds.\nWhat is the symbiotic potential of the focus of your work within current or possible systems? #\rX + Y = ? (is x symbiotic with y? Will it logically/plausibly fit?). In other words what is the likelihood of x and y being amenable to symbiosis? We asked participants to assess how symbiotic their projected outcome was in relation to the present. The present or current system, here, might refer to normative facts, natural facts or general subjective observations about the way some set of relations works. For example, how symbiotic is the idea that robots will replace teachers to the way the education system works today (quantitative, qualitative or subjective observations). The point of this is to think about how amenable the projected outcome or idea is to symbiosis given what is the case or what might be the case at the present time. The term “symbiobility”, or amenability to symbiosis is, according to our purposes, the ability for one thing to enter into symbiotic union with other entities.\nThink about whether the focus of your work is Raw or Cooked:\nWe asked participants to reflect on specific data sets (in the test case these related to the future of education) and their ideas using a simple two part classification: the raw and the cooked. This exercise is based on Claude Levi Strauss’ idea contained in The Raw and the Cooked (1964). Extrapolating from his writing we used it as a metaphorical device in order to check the dynamic for a proposed change in a system relating to whether it seemed: new/old, subcultural/mainstream, emergent surprising/emergent recognised and/or fresh/played out.\nOpen Textured Analysis #\rWe asked participants to list A-E what the characteristic of some x was. A problem example might be the status of the university.\nA: A place for learning. B: A place to experiment. C: A place for meeting new people. D: A place to research what really interests you.\nE: A Business?\nDynamic Outcomes Mapping for the Focus of Your Work #\rIs it almost certain, highly likely, very good chance, probable, likely,probably we believe that, better than even, about even, we doubt that, improbable, unlikely, probably not, little chance, almost no chance, highly unlikely, chances are slight?\nWe asked participants to respond to the test data/ideas/arguments using the above outcome variables as guides. The goal here is to match outcomes of the future of x to the outcome variables in order to see how likely a given scenario is. Participants were able to match to as many or as little variables as they liked. If they disagreed, say because the variables were to simplistic, then we asked them to match to the closest one and give a further explanation as to why this was wrong.\nDynamic Outcomes Mapping - each bar refers to a different idea\rCounterfactual Analysis #\rLarge non discrete counterfactuals: Choose a different system, what does the problem look like in that system? So for example what does the university look like now if the western world adopted a post capitalist economic model in 1995. Creative counterfactuals: We asked participants to come up with a future timeline and -30 year history prior to the present: -30, -15, 0, 15, 30, 90, far future. Then we asked them to change -30 and -15 and map out how this would change the previous future timeline. Discrete counterfactuals: Pick a small change in a system and speculate how that might change history. Think about how its discrete, emergent from what? and/or surprising. Disparate Group Analysis #\rTake two social groups which are very different in nature and look at their responses to the focus of your work. We used the examples of children (5-6) and (11-12) and compared this to a similar set of questions asked to a transdisciplinary adult group of 23+.\nEthics #\rWhat are the ethical problems relating to the causal interaction of your focus with the world? What theoretical constructs do we think best account for what we ought to do? What is preferable? What relationship does our argument have with law or economics or politics? How do your arguments here relate to conceptual ethics?\nCultural Analysis #\rLook at the focus of your work through the following lenses:\nSubculture (outlier) analysis + story Dominant culture (regime) Popular emergent culture (imposter) Structures of power and implementation (how change happens). Our Framework #\rOur final framework\rBibliography #\rBell, Clive. (1914). Art.\nChalmers, David. (2011). Verbal Disputes. Philosophical Review. 120 (4). 515-566.\nHonavar, Vasant. Complex Adaptive Systems Group at Iowa State University, http://www.cs.iastate.edu/~honavar/alife.isu.html, (date accessed: 7 December, 2016).\nLevi Strauss, Claude. (1964). The Raw and the Cooked.\nMikulecky, D. 2001. The Emergence of Complexity: Science Coming of Age or Science Growing Old? Computers and Chemistry. 341-48\nPlato. Translated by Alan Bloom (1991). The Republic.\nPlunkett, David \u0026amp; Sundell, Timothy (2013). Disagreement and the Semantics of Normative and Evaluative Terms. Philosophers’ Imprint 13 (23).\nWeitz, Morris. (1956) The Role of Theory in Aesthetics. The Journal of Aesthetics and Art Criticism, Vol. 15, No. 1. (September), pp. 27-35.\nWittgenstein, Ludwig. (1953). Philosophical Investigations.\n","date":"1 January 2017","externalUrl":null,"permalink":"/projects/occhio/","section":"Projects","summary":"A possible methodology on approaching the unknown unknowns, namely, future wicked problems.","title":"OCCHIO","type":"projects"},{"content":"","date":"1 January 2017","externalUrl":null,"permalink":"/tags/post/","section":"Tags","summary":"","title":"Post","type":"tags"},{"content":"","date":"10 January 2016","externalUrl":null,"permalink":"/tags/design-research/","section":"Tags","summary":"","title":"Design Research","type":"tags"},{"content":"","date":"10 January 2016","externalUrl":null,"permalink":"/tags/future-forecasting/","section":"Tags","summary":"","title":"Future Forecasting","type":"tags"},{"content":"Future forecasting is a tool that the designer should use in their practice, to envision beyond the current framework of products, services and systems.\nThis is my Service Design MA thesis.\nI\u0026rsquo;m specifically interested in the ethical implications of future forecasting. Who gives the designer the moral high ground to decide other people\u0026rsquo;s lives?\nFurthermore, it is clear that an essential code of ethics doesn\u0026rsquo;t exist.\nAs a possible solution, I propose a non-essential, open-textured ethical framework, structured as an open manifesto. Find the PDF after the break.\nPrevious\rNext \u0026nbsp; \u0026nbsp;\r/ [pdf]\rView the PDF file here.\r","date":"10 January 2016","externalUrl":null,"permalink":"/projects/ffforthedesigner/","section":"Projects","summary":"Who gives the designer the moral high ground to decide other people\u0026rsquo;s lives?","title":"Future Forecasting: A Handbook for the Designer","type":"projects"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]