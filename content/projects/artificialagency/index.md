+++
title = 'Artificial Agency'
date = 2024-01-14T07:07:07+01:00
summary = "What if the algorithm would prevent the user from performing certain actions which are deemed unlayful or unethical?"
showSummary = true
categories = ["Post","Blog",]
tags = ["ethics","transhumanism","wearable"]
+++
Companies selling prosthetics with embedded AI systems already exist ([Blatchford - UK](https://www.blatchfordmobility.com/) , [Össur - Iceland](https://www.ossur.com/)).
What if the algorithm would prevent the user from performing certain actions which are deemed unlayful or "unethical"?

This is a project which shows the dychotomic nature of _persuasive technology_.

{{< youtubeLite id="P8ljD53BN54" label="Artificial Agency Introduction Video" >}}

Artificial Agency is a future company which manufactures prosthetics and augmented limbs, with embedded artificial intelligence which might prevent the user from performing "unethical" actions.

Is overriding a person's free will ever ethically acceptable?
In this context, who decides what is ethical/unethical?
If there isn’t an essential, contextually aware ethical algorithm, how can these problems be resolved?

{{< figure
    src="flowchart.png"
    alt="High-level flowchart for the decisions happening under the hood"
    caption="High-level flowchart for the decisions happening under the hood"
    >}}

To understand how heteronomous control feels like, I built a wearable device which through electromyography understands when the wearer is about to swing a punch and prevents the action by activating a TENS (transcuteneous electrical nerve stimulation) machine which cases the bicep and tricep to contract, effectively deviating the blow.

{{< youtubeLite id="X3eGwVdTBEQ" label="Artificial Agency Interaction Demo" >}}



